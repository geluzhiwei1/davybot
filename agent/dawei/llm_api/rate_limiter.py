# Copyright (c) 2025 æ ¼å¾‹è‡³å¾®
# SPDX-License-Identifier: AGPL-3.0-only

"""è‡ªé€‚åº”é€Ÿç‡é™åˆ¶å™¨

æä¾›ç”Ÿäº§çº§çš„ LLM API é€Ÿç‡é™åˆ¶åŠŸèƒ½ï¼Œæ”¯æŒå¤šç§ç­–ç•¥å’ŒåŠ¨æ€è°ƒæ•´ã€‚
"""

import asyncio
import time
from collections import deque
from dataclasses import dataclass
from enum import Enum

from dawei.logg.logging import get_logger

logger = get_logger(__name__)


class RateLimitStrategy(Enum):
    """é€Ÿç‡é™åˆ¶ç­–ç•¥"""

    TOKEN_BUCKET = "token_bucket"  # ä»¤ç‰Œæ¡¶
    SLIDING_WINDOW = "sliding_window"  # æ»‘åŠ¨çª—å£
    LEAKY_BUCKET = "leaky_bucket"  # æ¼æ¡¶


@dataclass
class RateLimitConfig:
    """é€Ÿç‡é™åˆ¶é…ç½®"""

    initial_rate: float = 5.0  # åˆå§‹é€Ÿç‡ (req/s)
    min_rate: float = 0.5  # æœ€å°é€Ÿç‡
    max_rate: float = 50.0  # æœ€å¤§é€Ÿç‡
    burst_capacity: int = 20  # çªå‘å®¹é‡

    # è‡ªé€‚åº”è°ƒæ•´å‚æ•°
    scale_up_factor: float = 1.2  # æ‰©å®¹å› å­
    scale_down_factor: float = 0.7  # ç¼©å®¹å› å­
    scale_up_threshold: int = 10  # æ‰©å®¹æˆåŠŸé˜ˆå€¼
    scale_down_threshold: int = 3  # ç¼©å®¹å¤±è´¥é˜ˆå€¼

    # é€Ÿç‡é™åˆ¶ç­–ç•¥
    strategy: RateLimitStrategy = RateLimitStrategy.SLIDING_WINDOW


class AdaptiveRateLimiter:
    """è‡ªé€‚åº”é€Ÿç‡é™åˆ¶å™¨

    ç‰¹æ€§ï¼š
    - åŠ¨æ€è°ƒæ•´è¯·æ±‚é€Ÿç‡
    - æ”¯æŒçªå‘æµé‡
    - åŸºäºå†å²æˆåŠŸç‡è‡ªåŠ¨æ‰©ç¼©å®¹
    - å¤šç§é€Ÿç‡é™åˆ¶ç­–ç•¥

    ä½¿ç”¨ç¤ºä¾‹ï¼š
        config = RateLimitConfig(initial_rate=5.0)
        limiter = AdaptiveRateLimiter(config)

        # è·å–ä»¤ç‰Œ
        success, wait_time = await limiter.acquire(timeout=30.0)
        if success:
            # æ‰§è¡Œè¯·æ±‚
            await call_llm_api()
            limiter.record_success()
        else:
            limiter.record_failure()
    """

    def __init__(self, config: RateLimitConfig):
        self.config = config
        self._current_rate = config.initial_rate
        self._success_count = 0
        self._failure_count = 0
        self._last_adjust_time = time.time()

        # æ»‘åŠ¨çª—å£ï¼šè®°å½•æœ€è¿‘çš„è¯·æ±‚æ—¶é—´æˆ³
        self._request_history = deque(maxlen=config.burst_capacity)

        # ç»Ÿè®¡ä¿¡æ¯
        self._total_requests = 0
        self._total_successes = 0
        self._total_failures = 0
        self._total_rate_limit_errors = 0

        logger.info(
            f"AdaptiveRateLimiter initialized: initial_rate={config.initial_rate}, strategy={config.strategy.value}",
        )

    async def acquire(
        self,
        tokens: int = 1,
        timeout: float | None = None,
    ) -> tuple[bool, float | None]:
        """è·å–ä»¤ç‰Œ

        Args:
            tokens: éœ€è¦çš„ä»¤ç‰Œæ•°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºä¸ç­‰å¾…

        Returns:
            (success, wait_time): æ˜¯å¦æˆåŠŸ, ç­‰å¾…æ—¶é—´

        """
        start_time = time.time()

        while True:
            # å°è¯•è·å–ä»¤ç‰Œ
            success, wait_time = self._try_acquire(tokens)

            if success:
                self._total_requests += 1
                return True, wait_time

            # ä»¤ç‰Œä¸è¶³
            if timeout is None:
                # ä¸ç­‰å¾…ï¼Œç›´æ¥å¤±è´¥
                return False, wait_time

            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            elapsed = time.time() - start_time
            if elapsed >= timeout:
                logger.warning(
                    f"Rate limiter timeout after {elapsed:.1f}s, current_rate={self._current_rate:.2f}",
                )
                return False, wait_time

            # ç­‰å¾…åé‡è¯•
            wait_time = min(wait_time, timeout - elapsed)
            await asyncio.sleep(wait_time)

    def _try_acquire(self, tokens: int) -> tuple[bool, float]:
        """å°è¯•è·å–ä»¤ç‰Œï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        now = time.time()

        if self.config.strategy == RateLimitStrategy.SLIDING_WINDOW:
            return self._sliding_window_acquire(now, tokens)
        if self.config.strategy == RateLimitStrategy.TOKEN_BUCKET:
            return self._token_bucket_acquire(now, tokens)
        return self._leaky_bucket_acquire(now, tokens)

    def _sliding_window_acquire(self, now: float, tokens: int) -> tuple[bool, float]:
        """æ»‘åŠ¨çª—å£ç®—æ³•

        åŸç†ï¼šç»Ÿè®¡å½“å‰çª—å£å†…çš„è¯·æ±‚æ•°ï¼Œåˆ¤æ–­æ˜¯å¦å…è®¸æ–°è¯·æ±‚
        """
        # æ¸…ç†è¿‡æœŸè¯·æ±‚ï¼ˆè¶…è¿‡1ç§’çš„è¯·æ±‚ï¼‰
        while self._request_history and now - self._request_history[0] > 1.0:
            self._request_history.popleft()

        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é€Ÿç‡é™åˆ¶ï¼ˆå¤„ç†é›¶é€Ÿç‡è¾¹ç•Œï¼‰
        window_size = len(self._request_history)
        max_requests = max(1, int(self._current_rate))  # ç¡®ä¿è‡³å°‘ä¸º1

        if window_size + tokens <= max_requests:
            # å…è®¸è¯·æ±‚
            for _ in range(tokens):
                self._request_history.append(now)
            return True, 0.0
        # è®¡ç®—éœ€è¦ç­‰å¾…çš„æ—¶é—´
        if window_size >= max_requests:
            # çª—å£å·²æ»¡ï¼Œç­‰å¾…æœ€è€çš„è¯·æ±‚è¿‡æœŸ
            oldest_request = self._request_history[0]
            wait_time = max(0.01, 1.0 - (now - oldest_request) + 0.01)
        else:
            # çª—å£æœªæ»¡ï¼Œä½†å‰©ä½™å®¹é‡ä¸è¶³
            remaining_capacity = max_requests - window_size
            if remaining_capacity >= tokens:
                wait_time = 0.1  # çŸ­æš‚ç­‰å¾…
            else:
                # éœ€è¦ç­‰å¾…éƒ¨åˆ†å®¹é‡é‡Šæ”¾
                wait_time = 0.5

        return False, wait_time

    def _token_bucket_acquire(self, now: float, tokens: int) -> tuple[bool, float]:
        """ä»¤ç‰Œæ¡¶ç®—æ³•

        åŸç†ï¼šä»¥å›ºå®šé€Ÿç‡å‘æ¡¶ä¸­æ·»åŠ ä»¤ç‰Œï¼Œè¯·æ±‚æ—¶ä»æ¡¶ä¸­å–ä»¤ç‰Œ
        """
        # è®¡ç®—éœ€è¦è¡¥å……çš„ä»¤ç‰Œæ•°
        if not hasattr(self, "_last_refill_time"):
            self._last_refill_time = now

        elapsed = max(0, now - self._last_refill_time)  # ç¡®ä¿ä¸ä¼šä¸ºè´Ÿå€¼
        tokens_to_add = elapsed * self._current_rate

        # è·å–å½“å‰ä»¤ç‰Œæ•°
        if not hasattr(self, "_bucket_tokens"):
            self._bucket_tokens = float(self.config.burst_capacity)

        # è¡¥å……ä»¤ç‰Œï¼ˆç¡®ä¿ä¸ä¼šå‡ºç°è´Ÿå€¼ï¼‰
        self._bucket_tokens = min(
            self.config.burst_capacity,
            max(0.0, self._bucket_tokens + tokens_to_add),
        )
        self._last_refill_time = now

        # æ£€æŸ¥ä»¤ç‰Œæ˜¯å¦è¶³å¤Ÿ
        if self._bucket_tokens >= tokens:
            self._bucket_tokens -= tokens
            return True, 0.0
        # è®¡ç®—éœ€è¦ç­‰å¾…çš„æ—¶é—´ï¼ˆç¡®ä¿ä¸ä¼šå‡ºç°è´Ÿå€¼ï¼‰
        wait_time = max(0.01, (tokens - self._bucket_tokens) / self._current_rate)
        return False, wait_time

    def _leaky_bucket_acquire(self, now: float, tokens: int) -> tuple[bool, float]:
        """æ¼æ¡¶ç®—æ³•

        åŸç†ï¼šä»¥å›ºå®šé€Ÿç‡å¤„ç†è¯·æ±‚ï¼Œè¯·æ±‚è¿›å…¥æ¡¶ä¸­ç­‰å¾…å¤„ç†
        """
        # ç®€åŒ–å®ç°ï¼šä½¿ç”¨æ»‘åŠ¨çª—å£æ¨¡æ‹Ÿæ¼æ¡¶
        return self._sliding_window_acquire(now, tokens)

    def record_success(self):
        """è®°å½•æˆåŠŸè¯·æ±‚"""
        self._success_count += 1
        self._failure_count = 0
        self._total_successes += 1

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥æå‡é€Ÿç‡
        if self._success_count >= self.config.scale_up_threshold:
            self._adjust_rate(up=True)
            self._success_count = 0

    def record_failure(self, is_rate_limit: bool = False):
        """è®°å½•å¤±è´¥è¯·æ±‚"""
        self._failure_count += 1
        self._success_count = 0
        self._total_failures += 1

        if is_rate_limit:
            self._total_rate_limit_errors += 1
            # é€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œç«‹å³å¤§å¹…é™ä½
            self._current_rate = max(self.config.min_rate, self._current_rate * 0.5)
            # ä¸é‡ç½®å¤±è´¥è®¡æ•°ï¼Œè®©é—®é¢˜æŒç»­æš´éœ²
            # self._failure_count = 0  # å·²ç§»é™¤ï¼šéµå¾ª FAST FAIL åŸåˆ™
            logger.warning(
                f"Rate limit hit! Reduced rate to {self._current_rate:.2f}, failure_count={self._failure_count}",
            )
        elif self._failure_count >= self.config.scale_down_threshold:
            # è¿ç»­å¤±è´¥ï¼Œé€‚åº¦é™ä½
            self._adjust_rate(up=False)
            self._failure_count = 0

    def _adjust_rate(self, up: bool):
        """è°ƒæ•´é€Ÿç‡"""
        old_rate = self._current_rate

        if up:
            new_rate = self._current_rate * self.config.scale_up_factor
            self._current_rate = min(self.config.max_rate, max(self.config.min_rate, new_rate))
        else:
            new_rate = self._current_rate * self.config.scale_down_factor
            self._current_rate = max(self.config.min_rate, min(self.config.max_rate, new_rate))

        self._last_adjust_time = time.time()

        logger.info(
            f"Rate adjusted: {old_rate:.2f} -> {self._current_rate:.2f} ({'+ğŸ’ª' if up else '-ğŸ”»'})",
        )

    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        success_rate = 0.0
        if self._total_requests > 0:
            success_rate = self._total_successes / self._total_requests

        return {
            "current_rate": self._current_rate,
            "total_requests": self._total_requests,
            "total_successes": self._total_successes,
            "total_failures": self._total_failures,
            "total_rate_limit_errors": self._total_rate_limit_errors,
            "success_rate": success_rate,
            "strategy": self.config.strategy.value,
        }

    def reset(self):
        """é‡ç½®é€Ÿç‡é™åˆ¶å™¨"""
        self._current_rate = self.config.initial_rate
        self._success_count = 0
        self._failure_count = 0
        self._request_history.clear()

        if hasattr(self, "_bucket_tokens"):
            delattr(self, "_bucket_tokens")
        if hasattr(self, "_last_refill_time"):
            delattr(self, "_last_refill_time")

        logger.info("Rate limiter reset")
