# Copyright (c) 2025 æ ¼å¾‹è‡³å¾®
# SPDX-License-Identifier: AGPL-3.0-only

"""æµæ¶ˆæ¯å¤„ç†å™¨

å¤„ç†æµå¼æ•°æ®ä¼ è¾“ï¼Œæ”¯æŒå¤§æ–‡ä»¶ä¼ è¾“å’Œå®æ—¶æ•°æ®æµã€‚
"""

import json
import logging
from io import BytesIO
from typing import Any

from dawei.websocket.protocol import (
    BaseWebSocketMessage,
    ErrorMessage,
    MessageType,
    TaskNodeCompleteMessage,
    TaskNodeProgressMessage,
    TaskNodeStartMessage,
)

from .base import AsyncMessageHandler, StatefulMessageHandler

logger = logging.getLogger(__name__)


class StreamHandler(AsyncMessageHandler, StatefulMessageHandler):
    """æµæ¶ˆæ¯å¤„ç†å™¨"""

    def __init__(self, max_chunk_size: int = 8192, max_concurrent_streams: int = 5):
        AsyncMessageHandler.__init__(self, max_concurrent_tasks=max_concurrent_streams)
        StatefulMessageHandler.__init__(self)

        self.max_chunk_size = max_chunk_size
        self.active_streams: dict[str, dict[str, Any]] = {}

    def get_supported_types(self) -> list[str]:
        """è·å–æ”¯æŒçš„æ¶ˆæ¯ç±»å‹"""
        return [
            MessageType.TASK_NODE_START,
            MessageType.TASK_NODE_PROGRESS,
            MessageType.TASK_NODE_COMPLETE,
            MessageType.ERROR,
        ]

    async def on_initialize(self):
        """åˆå§‹åŒ–æ—¶çš„å›è°ƒ"""
        await super().on_initialize()
        await self.set_state("initialized", True)
        logger.info("æµå¤„ç†å™¨å·²åˆå§‹åŒ–")

    async def process_message(
        self,
        session_id: str,
        message: BaseWebSocketMessage,
    ) -> BaseWebSocketMessage | None:
        """å¤„ç†æµæ¶ˆæ¯

        Args:
            session_id: ä¼šè¯ID
            message: æµæ¶ˆæ¯

        Returns:
            å¯é€‰çš„å“åº”æ¶ˆæ¯

        """
        message_type = message.type

        if message_type == MessageType.TASK_NODE_START:
            return await self._handle_stream_start(session_id, message)
        if message_type == MessageType.TASK_NODE_PROGRESS:
            return await self._handle_stream_data(session_id, message)
        if message_type == MessageType.TASK_NODE_COMPLETE:
            return await self._handle_stream_end(session_id, message)
        if message_type == MessageType.ERROR:
            return await self._handle_stream_error(session_id, message)
        logger.warning(f"ä¸æ”¯æŒçš„æµæ¶ˆæ¯ç±»å‹: {message_type}")
        return None

    async def _handle_stream_start(
        self,
        session_id: str,
        message: BaseWebSocketMessage,
    ) -> BaseWebSocketMessage | None:
        """å¤„ç†æµå¼€å§‹æ¶ˆæ¯

        Args:
            session_id: ä¼šè¯ID
            message: æµå¼€å§‹æ¶ˆæ¯

        Returns:
            å¯é€‰çš„å“åº”æ¶ˆæ¯

        """
        if not isinstance(message, TaskNodeStartMessage):
            return None

        stream_id = message.task_id
        task_node_id = message.task_node_id

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥æµ
        if stream_id in self.active_streams:
            logger.warning(f"æµ {stream_id} å·²å­˜åœ¨")
            return await self.send_error_message(
                session_id,
                "STREAM_ALREADY_EXISTS",
                f"æµ {stream_id} å·²å­˜åœ¨",
                {"stream_id": stream_id},
            )

        # åˆ›å»ºæ–°çš„æµ
        self.active_streams[stream_id] = {
            "session_id": session_id,
            "stream_id": stream_id,
            "started_at": message.timestamp,
            "data": BytesIO(),
            "size": 0,
            "chunks": 0,
            "status": "active",
        }

        # æ›´æ–°å¤„ç†å™¨çŠ¶æ€
        await self.set_state(
            f"stream_{stream_id}",
            {
                "status": "started",
                "session_id": session_id,
                "started_at": message.timestamp,
            },
        )

        logger.info(f"å·²å¼€å§‹æµ {stream_id} for session {session_id}")

        # å‘é€ç¡®è®¤æ¶ˆæ¯
        return TaskNodeStartMessage(
            session_id=session_id,
            task_id=stream_id or task_node_id,  # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ node_idï¼Œå¦‚æœ stream_id ä¸ºç©º
            task_node_id=task_node_id,
            node_type="stream",
            description=f"æµ {stream_id} å·²å¼€å§‹",
        )

    async def _handle_stream_data(
        self,
        session_id: str,
        message: BaseWebSocketMessage,
    ) -> BaseWebSocketMessage | None:
        """å¤„ç†æµæ•°æ®æ¶ˆæ¯

        Args:
            session_id: ä¼šè¯ID
            message: æµæ•°æ®æ¶ˆæ¯

        Returns:
            å¯é€‰çš„å“åº”æ¶ˆæ¯

        """
        if not isinstance(message, TaskNodeProgressMessage):
            return None

        stream_id = message.task_id
        task_node_id = message.task_node_id

        # æ£€æŸ¥æµæ˜¯å¦å­˜åœ¨
        if stream_id not in self.active_streams:
            logger.warning(f"æµ {stream_id} ä¸å­˜åœ¨")
            return await self.send_error_message(
                session_id,
                "STREAM_NOT_FOUND",
                f"æµ {stream_id} ä¸å­˜åœ¨",
                {"stream_id": stream_id},
            )

        stream_info = self.active_streams[stream_id]

        # æ£€æŸ¥æµçŠ¶æ€
        if stream_info["status"] != "active":
            logger.warning(f"æµ {stream_id} çŠ¶æ€ä¸æ­£ç¡®: {stream_info['status']}")
            return await self.send_error_message(
                session_id,
                "STREAM_NOT_ACTIVE",
                f"æµ {stream_id} ä¸å¤„äºæ´»è·ƒçŠ¶æ€",
                {"stream_id": stream_id, "status": stream_info["status"]},
            )

        # è·å–æ•°æ®
        data = message.data or {}
        chunk_data = data.get("chunk", "")

        if isinstance(chunk_data, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—èŠ‚
            chunk_bytes = chunk_data.encode("utf-8")
        elif isinstance(chunk_data, bytes):
            chunk_bytes = chunk_data
        else:
            # å…¶ä»–ç±»å‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²å†ç¼–ç 
            chunk_bytes = str(chunk_data).encode("utf-8")

        # å†™å…¥æ•°æ®
        stream_info["data"].write(chunk_bytes)
        stream_info["size"] += len(chunk_bytes)
        stream_info["chunks"] += 1

        # æ›´æ–°å¤„ç†å™¨çŠ¶æ€
        await self.set_state(
            f"stream_{stream_id}",
            {
                "status": "streaming",
                "size": stream_info["size"],
                "chunks": stream_info["chunks"],
            },
        )

        # æ£€æŸ¥å¤§å°é™åˆ¶
        max_size = await self.get_state("max_stream_size", 100 * 1024 * 1024)  # é»˜è®¤100MB
        if stream_info["size"] > max_size:
            logger.warning(f"æµ {stream_id} è¶…è¿‡å¤§å°é™åˆ¶")
            await self._cleanup_stream(stream_id)
            return await self.send_error_message(
                session_id,
                "STREAM_TOO_LARGE",
                f"æµ {stream_id} è¶…è¿‡å¤§å°é™åˆ¶",
                {
                    "stream_id": stream_id,
                    "size": stream_info["size"],
                    "max_size": max_size,
                },
            )

        # å‘é€è¿›åº¦ç¡®è®¤
        return TaskNodeProgressMessage(
            session_id=session_id,
            task_id=message.task_id,
            task_node_id=task_node_id,
            progress=message.progress,
            status="streaming",
            message=f"å·²æ¥æ”¶ {stream_info['chunks']} ä¸ªæ•°æ®å—ï¼Œæ€»è®¡ {stream_info['size']} å­—èŠ‚",
            data={"chunks": stream_info["chunks"], "size": stream_info["size"]},
        )

    async def _handle_stream_end(
        self,
        session_id: str,
        message: BaseWebSocketMessage,
    ) -> BaseWebSocketMessage | None:
        """å¤„ç†æµç»“æŸæ¶ˆæ¯

        Args:
            session_id: ä¼šè¯ID
            message: æµç»“æŸæ¶ˆæ¯

        Returns:
            å¯é€‰çš„å“åº”æ¶ˆæ¯

        """
        if not isinstance(message, TaskNodeCompleteMessage):
            return None

        stream_id = message.task_id
        task_node_id = message.task_node_id

        # æ£€æŸ¥æµæ˜¯å¦å­˜åœ¨
        if stream_id not in self.active_streams:
            logger.warning(f"æµ {stream_id} ä¸å­˜åœ¨")
            return await self.send_error_message(
                session_id,
                "STREAM_NOT_FOUND",
                f"æµ {stream_id} ä¸å­˜åœ¨",
                {"stream_id": stream_id},
            )

        stream_info = self.active_streams[stream_id]

        # è·å–å®Œæ•´æ•°æ®
        stream_info["data"].seek(0)
        complete_data = stream_info["data"].read()

        # å¤„ç†å®Œæ•´æ•°æ®
        try:
            result = await self._process_complete_data(
                session_id,
                stream_id,
                complete_data,
                message.result or {},
            )

            # æ›´æ–°æµçŠ¶æ€
            stream_info["status"] = "completed"

            # æ›´æ–°å¤„ç†å™¨çŠ¶æ€
            await self.set_state(
                f"stream_{stream_id}",
                {
                    "status": "completed",
                    "size": stream_info["size"],
                    "chunks": stream_info["chunks"],
                    "result": result,
                },
            )

            # æ¸…ç†æµ
            await self._cleanup_stream(stream_id)

            logger.info(f"æµ {stream_id} å·²å®Œæˆï¼Œæ€»è®¡ {stream_info['size']} å­—èŠ‚")

            # å‘é€å®Œæˆç¡®è®¤
            return TaskNodeCompleteMessage(
                session_id=session_id,
                task_id=stream_id or task_node_id,  # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ node_idï¼Œå¦‚æœ stream_id ä¸ºç©º
                task_node_id=task_node_id,
                result={
                    "status": "completed",
                    "size": stream_info["size"],
                    "chunks": stream_info["chunks"],
                    "result": result,
                },
                duration_ms=0,
            )

        except (ValueError, json.JSONDecodeError, UnicodeDecodeError) as e:
            logger.error(f"å¤„ç†æµæ•°æ®æ—¶å‡ºé”™: {e}", exc_info=True)

            # æ¸…ç†æµ
            await self._cleanup_stream(stream_id)

            return await self.send_error_message(
                session_id,
                "STREAM_PROCESSING_ERROR",
                f"å¤„ç†æµæ•°æ®æ—¶å‡ºé”™: {e!s}",
                {"stream_id": stream_id},
            )

    async def _handle_stream_error(
        self,
        session_id: str,
        message: BaseWebSocketMessage,
    ) -> BaseWebSocketMessage | None:
        """å¤„ç†æµé”™è¯¯æ¶ˆæ¯

        Args:
            session_id: ä¼šè¯ID
            message: æµé”™è¯¯æ¶ˆæ¯

        Returns:
            å¯é€‰çš„å“åº”æ¶ˆæ¯

        """
        if not isinstance(message, ErrorMessage):
            return None

        # æ¸…ç†æµ - ä»é”™è¯¯æ¶ˆæ¯çš„detailsä¸­è·å–stream_id
        stream_id = None
        if message.details and "stream_id" in message.details:
            stream_id = message.details["stream_id"]

        if stream_id and stream_id in self.active_streams:
            await self._cleanup_stream(stream_id)

            # æ›´æ–°å¤„ç†å™¨çŠ¶æ€
            await self.set_state(
                f"stream_{stream_id}",
                {"status": "error", "error": message.message, "code": message.code},
            )

            logger.error(f"æµ {stream_id} å‘ç”Ÿé”™è¯¯: {message.message}")

        # å‘é€é”™è¯¯ç¡®è®¤
        return ErrorMessage(
            session_id=session_id,
            code=message.code,
            message=f"æµé”™è¯¯å·²ç¡®è®¤: {message.message}",
            details=message.details,
            recoverable=message.recoverable,
        )

    async def _process_complete_data(
        self,
        _session_id: str,
        _stream_id: str,
        data: bytes,
        metadata: dict[str, Any],
    ) -> dict[str, Any]:
        """å¤„ç†å®Œæ•´çš„æ•°æ®

        Args:
            session_id: ä¼šè¯ID
            stream_id: æµID
            data: å®Œæ•´æ•°æ®
            metadata: å…ƒæ•°æ®

        Returns:
            å¤„ç†ç»“æœ

        """
        # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…éœ€æ±‚å¤„ç†æ•°æ®
        # ä¾‹å¦‚ï¼šä¿å­˜åˆ°æ–‡ä»¶ã€è§£æå†…å®¹ã€è°ƒç”¨å…¶ä»–æœåŠ¡ç­‰

        try:
            # ç¤ºä¾‹ï¼šå°è¯•è§£æä¸ºJSON
            if data.startswith(b"{") and data.endswith(b"}"):
                import json

                json_data = json.loads(data.decode("utf-8"))
                return {"type": "json", "data": json_data, "size": len(data)}

            # ç¤ºä¾‹ï¼šå°è¯•è§£æä¸ºæ–‡æœ¬
            try:
                text_data = data.decode("utf-8")
                return {
                    "type": "text",
                    "data": text_data,
                    "size": len(data),
                    "lines": len(text_data.split("\n")),
                }
            except UnicodeDecodeError:
                pass

            # é»˜è®¤ï¼šä½œä¸ºäºŒè¿›åˆ¶æ•°æ®å¤„ç†
            return {"type": "binary", "size": len(data), "metadata": metadata}

        except (ValueError, json.JSONDecodeError, UnicodeDecodeError) as e:
            logger.error(f"å¤„ç†å®Œæ•´æ•°æ®æ—¶å‡ºé”™: {e}", exc_info=True)
            raise

    async def _cleanup_stream(self, stream_id: str):
        """æ¸…ç†æµèµ„æº

        Args:
            stream_id: æµID

        """
        if stream_id in self.active_streams:
            stream_info = self.active_streams[stream_id]

            # å…³é—­æ•°æ®æµ
            if hasattr(stream_info["data"], "close"):
                stream_info["data"].close()

            # ä»æ´»è·ƒæµä¸­ç§»é™¤
            del self.active_streams[stream_id]

            # æ¸…ç†å¤„ç†å™¨çŠ¶æ€
            await self.set_state(f"stream_{stream_id}", None)

    async def get_stream_info(self, stream_id: str) -> dict[str, Any] | None:
        """è·å–æµä¿¡æ¯

        Args:
            stream_id: æµID

        Returns:
            æµä¿¡æ¯ï¼Œä¸å­˜åœ¨è¿”å›None

        """
        return self.active_streams.get(stream_id)

    async def get_active_streams(self) -> list[dict[str, Any]]:
        """è·å–æ‰€æœ‰æ´»è·ƒæµ

        Returns:
            æ´»è·ƒæµåˆ—è¡¨

        """
        return [
            {
                "stream_id": stream_id,
                "session_id": info["session_id"],
                "size": info["size"],
                "chunks": info["chunks"],
                "status": info["status"],
                "started_at": info["started_at"],
            }
            for stream_id, info in self.active_streams.items()
        ]

    async def set_max_stream_size(self, max_size: int):
        """è®¾ç½®æœ€å¤§æµå¤§å°

        Args:
            max_size: æœ€å¤§å¤§å°ï¼ˆå­—èŠ‚ï¼‰

        """
        await self.set_state("max_stream_size", max_size)
        logger.info(f"å·²è®¾ç½®æœ€å¤§æµå¤§å°: {max_size} å­—èŠ‚")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        # æ¸…ç†æ‰€æœ‰æ´»è·ƒæµ
        for stream_id in list(self.active_streams.keys()):
            await self._cleanup_stream(stream_id)

        # æ¸…ç†çŠ¶æ€
        await self.clear_state()

        # è°ƒç”¨çˆ¶ç±»æ¸…ç†
        await super().cleanup()

        logger.info("æµå¤„ç†å™¨å·²æ¸…ç†")
