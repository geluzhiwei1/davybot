# Copyright (c) 2025 æ ¼å¾‹è‡³å¾®
# SPDX-License-Identifier: AGPL-3.0-only

"""ç”¨æˆ·å·¥ä½œåŒºå®žä½“ç±» - é‡æž„ç‰ˆæœ¬

æä¾›å·¥ä½œåŒºç®¡ç†ã€å¯¹è¯ç®¡ç†ã€é…ç½®åŠ è½½å’Œå·¥å…·é›†æˆåŠŸèƒ½
æ ¸å¿ƒç‰¹æ€§ï¼š
- æŒæœ‰Conversationå±žæ€§ä½œä¸ºå½“å‰å¯¹è¯
- æŒæœ‰ConversationHistoryManagerç®¡ç†åŽ†å²å¯¹è¯
- æ”¯æŒå·¥ä½œåŒºç”Ÿå‘½å‘¨æœŸç®¡ç†
- ä¸è€ƒè™‘åŽå‘å…¼å®¹
"""

import asyncio
import json
import logging
import os
import uuid
from datetime import UTC, datetime, timezone
from pathlib import Path
from typing import TYPE_CHECKING, Any

from dawei.config import get_dawei_home
from dawei.conversation.conversation import Conversation, create_conversation
# from dawei.core.events import CORE_EVENT_BUS  # REMOVED: CORE_EVENT_BUS deleted
from dawei.entity.llm_config import LLMConfig
from dawei.task_graph.task_node_data import TaskContext
from dawei.tools.mcp_tool_manager import MCPConfig, MCPToolManager

from .exceptions import (
    ConversationPersistenceError,
    TaskGraphPersistenceError,
    WorkspaceInfoPersistenceError,
)
from .models import WorkspaceInfo, WorkspaceSettings
from .persistence_manager import ResourceType, WorkspacePersistenceManager

logger = logging.getLogger(__name__)

# Import super mode utilities
from dawei.core.super_mode import is_super_mode_enabled, log_security_bypass

if TYPE_CHECKING:
    from dawei.conversation.conversation_history_manager import (
        ConversationHistoryManager,
    )
    from dawei.llm_api.llm_provider import LLMProvider
    from dawei.tools.tool_manager import ToolManager


class UserWorkspace:
    """ç”¨æˆ·å·¥ä½œåŒºç±» - é‡æž„ç‰ˆæœ¬

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    - æŒæœ‰Conversationå±žæ€§ä½œä¸ºå½“å‰å¯¹è¯
    - æŒæœ‰ConversationHistoryManagerç®¡ç†åŽ†å²å¯¹è¯
    - æ”¯æŒå·¥ä½œåŒºç”Ÿå‘½å‘¨æœŸç®¡ç†
    - æä¾›é…ç½®åŠ è½½å’Œå·¥å…·é›†æˆåŠŸèƒ½
    """

    def __init__(self, workspace_path: str):
        """åˆå§‹åŒ–ç”¨æˆ·å·¥ä½œåŒº

        Args:
            workspace_path: å·¥ä½œåŒºè·¯å¾„

        """
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"UserWorkspace __init__ called for path: {workspace_path}")

        # åŸºæœ¬è·¯å¾„ä¿¡æ¯
        self.workspace_path = Path(workspace_path).resolve()
        self.absolute_path = str(self.workspace_path)
        self.uuid = str(uuid.uuid4())

        # â­ æ–°å¢žï¼šWorkspaceContext å¼•ç”¨ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
        self._context = None

        # å·¥ä½œåŒºä¿¡æ¯
        self.workspace_info: WorkspaceInfo | None = None

        # æŒä¹…åŒ–ç®¡ç†å™¨ - çŽ°åœ¨ä»Ž context èŽ·å–ï¼ˆå‘åŽå…¼å®¹ï¼‰
        self.persistence_manager: WorkspacePersistenceManager | None = None

        # TaskGraph è‡ªåŠ¨æŒä¹…åŒ–ç®¡ç†å™¨ - çŽ°åœ¨ä»Ž context èŽ·å–ï¼ˆå‘åŽå…¼å®¹ï¼‰
        self.task_graph_persistence_manager = None

        # å¯¹è¯ç®¡ç† - æ ¸å¿ƒåŠŸèƒ½
        self.current_conversation: Conversation | None = None
        self.conversation_history_manager: ConversationHistoryManager | None = None

        # è‡ªåŠ¨ä¿å­˜æœºåˆ¶
        self._auto_save_task: asyncio.Task | None = None
        self._auto_save_interval = 30  # é»˜è®¤30ç§’è‡ªåŠ¨ä¿å­˜ä¸€æ¬¡
        self._last_message_count = 0  # ä¸Šæ¬¡ä¿å­˜æ—¶çš„æ¶ˆæ¯æ•°é‡
        self._auto_save_enabled = True  # æ˜¯å¦å¯ç”¨è‡ªåŠ¨ä¿å­˜

        # æŒä¹…åŒ–é‡è¯•æœºåˆ¶
        self._max_retry_attempts = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
        self._retry_base_delay = 1.0  # åŸºç¡€é‡è¯•å»¶è¿Ÿ(ç§’)
        self._retry_max_delay = 30.0  # æœ€å¤§é‡è¯•å»¶è¿Ÿ(ç§’)
        self._retry_backoff_multiplier = 2.0  # é€€é¿ä¹˜æ•°

        # UI ä¸Šä¸‹æ–‡è‡ªåŠ¨ä¿å­˜
        self._ui_context_dirty = False  # UI ä¸Šä¸‹æ–‡æ˜¯å¦éœ€è¦ä¿å­˜

        # é…ç½®è·¯å¾„å®šä¹‰
        self.user_config_dir = self.workspace_path / ".dawei"
        self.settings_file = self.user_config_dir / "settings.json"
        self.workspace_info_file = self.workspace_path / ".dawei" / "workspace.json"
        self.chat_history_dir = self.workspace_path / ".dawei" / "chat-history"
        self.tasks_file = self.workspace_path / ".dawei" / "tasks.json"

        # é…ç½®æ•°æ®
        self.workspace_settings: WorkspaceSettings | None = None

        # âœ¨ æ–°å¢žï¼šç»Ÿä¸€å·¥ä½œåŒºé…ç½®ï¼ˆPydantic æ¨¡åž‹ï¼‰
        from .models import PluginsConfig, WorkspaceConfig

        self.workspace_config: WorkspaceConfig | None = None
        self.plugins_config: PluginsConfig | None = None  # âœ¨ æ–°å¢žï¼šæ’ä»¶é…ç½®ï¼ˆç‹¬ç«‹æ–‡ä»¶ï¼‰

        # LLM ç®¡ç† - ç”± LLMProvider ç»Ÿä¸€ç®¡ç†
        self.llm_manager: LLMProvider | None = None

        # å·¥å…·ç®¡ç† - ç”± ToolManager å’Œ MCPToolManager ç»Ÿä¸€ç®¡ç†
        self.tool_manager: ToolManager | None = None
        self.mcp_tool_manager: MCPToolManager | None = None

        # ðŸ”´ ä¿®å¤ï¼šUserWorkspace ä¸å†æ‹¥æœ‰ event_bus
        # æ‰€æœ‰ event_bus ç”± Agent åˆ›å»ºå’Œç®¡ç†ï¼Œé¿å…å¤šä¸ª Agent å…±äº« event_bus å¯¼è‡´çš„ handler å¹²æ‰°
        # self.event_bus = None  # ä¸å†éœ€è¦

        # Skillså·¥å…· - å•ç‹¬ç®¡ç†
        self._skills_tools: list | None = None

        # æ¨¡å¼ç®¡ç† - å»¶è¿Ÿåˆå§‹åŒ–ä»¥é¿å…å¾ªçŽ¯ä¾èµ–
        self._mode_manager = None

        # å®‰å…¨ç›¸å…³
        self._forbidden_paths: set[str] = set()
        self._allowed_commands_cache: set[str] | None = None

        # ç”Ÿå‘½å‘¨æœŸçŠ¶æ€
        self._initialized = False
        self._loaded = False

        # event_bus å·²åœ¨ __init__ å‰é¢è®¾ç½®ä¸ºç‹¬ç«‹å®žä¾‹ï¼ˆä¸ä½¿ç”¨å…¨å±€å•ä¾‹ï¼‰

        logger.info(f"UserWorkspace initialized: {self.absolute_path}")

    # ==================== WorkspaceContext å±žæ€§è®¿é—®ä»£ç† ====================

    @property
    def context(self):
        """èŽ·å–å·¥ä½œåŒºä¸Šä¸‹æ–‡ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._context is None:
            raise RuntimeError(f"Workspace not initialized. Call initialize() first. Workspace: {self.absolute_path}")
        return self._context

    @property
    def tool_manager(self):
        """å·¥å…·ç®¡ç†å™¨ï¼ˆä»Žå…±äº« context èŽ·å–ï¼‰"""
        # å‘åŽå…¼å®¹ï¼šå¦‚æžœå·²æœ‰ç›´æŽ¥å¼•ç”¨ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä»Ž context èŽ·å–
        if hasattr(self, "_tool_manager_ref") and self._tool_manager_ref:
            return self._tool_manager_ref
        if self._context:
            return self._context.tool_manager
        # å¦‚æžœè¿˜æ²¡åˆå§‹åŒ–ï¼Œè¿”å›ž Noneï¼ˆå‘åŽå…¼å®¹ï¼‰
        return None

    @tool_manager.setter
    def tool_manager(self, value):
        """è®¾ç½®å·¥å…·ç®¡ç†å™¨ï¼ˆç”¨äºŽå‘åŽå…¼å®¹ï¼‰"""
        self._tool_manager_ref = value

    @property
    def llm_manager(self):
        """LLM ç®¡ç†å™¨ï¼ˆä»Žå…±äº« context èŽ·å–ï¼‰"""
        if hasattr(self, "_llm_manager_ref") and self._llm_manager_ref:
            return self._llm_manager_ref
        if self._context:
            return self._context.llm_manager
        return None

    @llm_manager.setter
    def llm_manager(self, value):
        """è®¾ç½® LLM ç®¡ç†å™¨ï¼ˆç”¨äºŽå‘åŽå…¼å®¹ï¼‰"""
        self._llm_manager_ref = value

    @property
    def persistence_manager(self):
        """æŒä¹…åŒ–ç®¡ç†å™¨ï¼ˆä»Žå…±äº« context èŽ·å–ï¼‰"""
        if self._context:
            return self._context.persistence_manager
        return None

    @persistence_manager.setter
    def persistence_manager(self, value):
        """è®¾ç½®æŒä¹…åŒ–ç®¡ç†å™¨ï¼ˆç”¨äºŽå‘åŽå…¼å®¹ï¼‰"""
        # ä¸ä¿å­˜ï¼Œå› ä¸ºçŽ°åœ¨ä»Ž context èŽ·å–

    @property
    def task_graph_persistence_manager(self):
        """TaskGraph æŒä¹…åŒ–ç®¡ç†å™¨ï¼ˆä»Žå…±äº« context èŽ·å–ï¼‰"""
        if self._context:
            return self._context.task_graph_persistence_manager
        return None

    @task_graph_persistence_manager.setter
    def task_graph_persistence_manager(self, value):
        """è®¾ç½® TaskGraph æŒä¹…åŒ–ç®¡ç†å™¨ï¼ˆç”¨äºŽå‘åŽå…¼å®¹ï¼‰"""
        # ä¸ä¿å­˜ï¼Œå› ä¸ºçŽ°åœ¨ä»Ž context èŽ·å–

    @property
    def workspace_settings(self):
        """å·¥ä½œåŒºé…ç½®ï¼ˆä»Žå…±äº« context èŽ·å–ï¼‰"""
        if self._context:
            return self._context.workspace_settings
        return None

    @workspace_settings.setter
    def workspace_settings(self, value):
        """è®¾ç½®å·¥ä½œåŒºé…ç½®ï¼ˆåŒæ­¥åˆ° contextï¼‰"""
        if self._context:
            self._context.workspace_settings = value
        # ä¿å­˜æœ¬åœ°å¼•ç”¨ï¼ˆå‘åŽå…¼å®¹ï¼‰
        self._workspace_settings_ref = value

    @property
    def conversation_history_manager(self):
        """å¯¹è¯åŽ†å²ç®¡ç†å™¨ï¼ˆä»Žå…±äº« context èŽ·å–ï¼‰"""
        if self._context:
            return self._context.conversation_history_manager
        return None

    @conversation_history_manager.setter
    def conversation_history_manager(self, value):
        """è®¾ç½®å¯¹è¯åŽ†å²ç®¡ç†å™¨ï¼ˆç”¨äºŽå‘åŽå…¼å®¹ï¼‰"""
        # ä¸ä¿å­˜ï¼Œå› ä¸ºçŽ°åœ¨ä»Ž context èŽ·å–

    # ==================== åŽŸæœ‰æ–¹æ³• ====================

    def is_command_allowed(self, command: str) -> bool:
        """æ£€æŸ¥å‘½ä»¤æ˜¯å¦å…è®¸æ‰§è¡Œ

        Args:
            command: è¦æ£€æŸ¥çš„å‘½ä»¤å­—ç¬¦ä¸²

        Returns:
            bool: å‘½ä»¤æ˜¯å¦åœ¨å…è®¸åˆ—è¡¨ä¸­

        """
        # SUPER MODE: Allow all commands
        if is_super_mode_enabled():
            log_security_bypass("is_command_allowed", f"command={command}")
            return True

        if not command:
            return False

        # æå–å‘½ä»¤çš„ç¬¬ä¸€ä¸ªå•è¯ï¼ˆå‘½ä»¤åç§°ï¼‰
        command_parts = command.strip().split()
        if not command_parts:
            return False

        command_name = command_parts[0]

        # å¦‚æžœæœ‰ç¼“å­˜çš„å…è®¸å‘½ä»¤åˆ—è¡¨ï¼Œä½¿ç”¨ç¼“å­˜
        if self._allowed_commands_cache is not None:
            return command_name in self._allowed_commands_cache

        # ä»Žworkspace_settingsèŽ·å–å…è®¸çš„å‘½ä»¤
        if self.workspace_settings and hasattr(self.workspace_settings, "allowed_commands"):
            allowed_commands = self.workspace_settings.allowed_commands
            if allowed_commands:
                # ç¼“å­˜ç»“æžœ
                self._allowed_commands_cache = set(allowed_commands)
                return command_name in allowed_commands

        # å¦‚æžœæ²¡æœ‰é…ç½®å…è®¸çš„å‘½ä»¤ï¼Œé»˜è®¤å…è®¸æ‰€æœ‰å‘½ä»¤ï¼ˆå‘åŽå…¼å®¹ï¼‰
        logger.debug(
            f"is_command_allowed: no allowed_commands configured, allowing '{command_name}'",
        )
        return True

    @property
    def mode(self):
        """å½“å‰mode"""
        return self.workspace_info.user_ui_context.current_mode

    @mode.setter
    def mode(self, value):
        self.workspace_info.user_ui_context.current_mode = value

    @property
    def mode_manager(self):
        """å»¶è¿Ÿåˆå§‹åŒ– ModeManager ä»¥é¿å…å¾ªçŽ¯ä¾èµ–"""
        if self._mode_manager is None:
            from dawei.mode.mode_manager import ModeManager

            # ä¼ å…¥å·¥ä½œåŒºè·¯å¾„ä»¥æ”¯æŒå·¥ä½œåŒºçº§é…ç½®
            self._mode_manager = ModeManager(workspace_path=self.absolute_path)
        return self._mode_manager

    async def initialize(self) -> bool:
        """å¼‚æ­¥åˆå§‹åŒ–å·¥ä½œåŒºï¼ˆä½¿ç”¨ WorkspaceServiceï¼‰

        â­ æ”¹è¿›ï¼šä½¿ç”¨å…±äº«çš„ WorkspaceContextï¼Œé¿å…é‡å¤åˆ›å»ºèµ„æº

        Returns:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ

        """
        if self._initialized:
            return True

        logger.info(f"Initializing workspace: {self.absolute_path}")

        try:
            # â­ æ ¸å¿ƒæ”¹åŠ¨ï¼šèŽ·å–å…±äº«çš„ WorkspaceContextï¼ˆæ¯ä¸ª workspace_id ä¸€ä¸ªå•ä¾‹ï¼‰
            from .workspace_service import WorkspaceService

            self._context = await WorkspaceService.get_context(self.absolute_path)
            logger.info(f"  âœ“ Acquired WorkspaceContext (refs={self.context.ref_count})")

            # åŠ è½½å·¥ä½œåŒºä¿¡æ¯ï¼ˆä½¿ç”¨å…±äº«çš„ persistence_managerï¼‰
            await self._load_workspace_info()
            logger.info("  âœ“ Workspace info loaded")

            # åŠ è½½é…ç½®
            await self._load_configurations()
            logger.info("  âœ“ Configurations loaded")

            # åˆå§‹åŒ–å¯¹è¯ç®¡ç†ï¼ˆä½¿ç”¨å…±äº«çš„ conversation_history_managerï¼‰
            await self._initialize_conversation_management()
            logger.info("  âœ“ Conversation management initialized")

            # ðŸ”§ ä¿®å¤ï¼šä¸åœ¨ UserWorkspace åˆ›å»º TaskGraph
            # TaskGraph åº”è¯¥ç”± Agent åˆ›å»ºå¹¶ä½¿ç”¨ Agent çš„ event_bus
            # è¿™é‡Œè®¾ç½®ä¸º None,Agent ç¨åŽä¼šåˆ›å»ºè‡ªå·±çš„ TaskGraph
            self.task_graph = None
            logger.info("  âœ“ Task graph placeholder set (will be created by Agent)")

            # å¯åŠ¨å¯¹è¯è‡ªåŠ¨ä¿å­˜ä»»åŠ¡
            await self._start_auto_save_conversation()
            logger.info("  âœ“ Auto-save started")

            self._initialized = True
            self._loaded = True
            logger.info(f"âœ“ Workspace initialization completed successfully: {self.absolute_path}")
            return True

        except Exception as e:
            logger.error(f"Failed to initialize workspace: {e}", exc_info=True)
            # æ¸…ç†å·²èŽ·å–çš„ä¸Šä¸‹æ–‡
            if self._context:
                await self._context.release()
                self._context = None
            # å‘é€æŒä¹…åŒ–å¤±è´¥å‘Šè­¦
            await self._alert_persistence_failure("workspace_initialization", str(e))
            raise

    async def _initialize_persistence_manager(self):
        """åˆå§‹åŒ–æŒä¹…åŒ–ç®¡ç†å™¨ï¼ˆçŽ°åœ¨ä»Ž WorkspaceContext èŽ·å–ï¼‰

        â­ æ”¹åŠ¨ï¼šä¸å†åˆ›å»ºæŒä¹…åŒ–ç®¡ç†å™¨ï¼Œç›´æŽ¥ä½¿ç”¨ WorkspaceContext ä¸­çš„
        """
        # ä¸å†éœ€è¦åˆ›å»ºï¼Œpersistence_manager å·²ç»åœ¨ WorkspaceContext ä¸­åˆå§‹åŒ–
        # é€šè¿‡ @property persistence_manager è‡ªåŠ¨èŽ·å–
        logger.debug("Persistence manager provided by WorkspaceContext")

    async def _load_workspace_info(self):
        """åŠ è½½å·¥ä½œåŒºä¿¡æ¯ (ä½¿ç”¨æŒä¹…åŒ–ç®¡ç†å™¨)"""
        try:
            # é¦–å…ˆå°è¯•ä»Žæ–°çš„æŒä¹…åŒ–ç®¡ç†å™¨åŠ è½½
            if self.persistence_manager:
                workspace_data = await self.persistence_manager.load_resource(
                    ResourceType.WORKSPACE_INFO,
                    "workspace",
                )

                if workspace_data:
                    self.workspace_info = WorkspaceInfo.from_dict(workspace_data)
                    logger.info(
                        f"Loaded workspace info from persistence manager: {self.workspace_info.name}",
                    )
                    return

            # å›žé€€åˆ°æ—§æ ¼å¼æ–‡ä»¶
            if self.workspace_info_file.exists():
                with Path(self.workspace_info_file).open(encoding="utf-8") as f:
                    data = json.load(f)
                self.workspace_info = WorkspaceInfo.from_dict(data)
                logger.info(f"Loaded workspace info from legacy file: {self.workspace_info.name}")

                # è¿ç§»åˆ°æ–°çš„æŒä¹…åŒ–ç®¡ç†å™¨
                if self.persistence_manager:
                    await self._migrate_workspace_info_to_persistence_manager()
            else:
                # åˆ›å»ºé»˜è®¤å·¥ä½œåŒºä¿¡æ¯
                self.workspace_info = WorkspaceInfo(
                    id=str(uuid.uuid4()),
                    name=self.workspace_path.name,
                    display_name=self.workspace_path.name,
                    description=f"Workspace at {self.workspace_path}",
                    created_at=datetime.now(UTC),
                )
                await self._save_workspace_info()

        except Exception as e:
            logger.error(f"Failed to load workspace info: {e}", exc_info=True)
            raise WorkspaceInfoPersistenceError(
                f"Failed to load workspace info: {e}",
                workspace_id=self.uuid,
            )

    async def _save_workspace_info(self):
        """ä¿å­˜å·¥ä½œåŒºä¿¡æ¯ (ä½¿ç”¨æŒä¹…åŒ–ç®¡ç†å™¨)"""
        if not self.workspace_info:
            logger.warning("Cannot save workspace info: workspace_info is None")
            return False

        try:
            # ä½¿ç”¨æŒä¹…åŒ–ç®¡ç†å™¨ä¿å­˜
            if self.persistence_manager:
                success = await self.persistence_manager.save_resource(
                    ResourceType.WORKSPACE_INFO,
                    "workspace",
                    self.workspace_info.to_dict(),
                    use_timestamp=False,
                )

                if success:
                    logger.debug("Workspace info saved via persistence manager.")
                    return True
                raise WorkspaceInfoPersistenceError(
                    "Persistence manager returned False",
                    workspace_id=self.workspace_info.id,
                )

        except Exception as e:
            logger.error(f"Failed to save workspace info: {e}", exc_info=True)
            # å‘é€æŒä¹…åŒ–å¤±è´¥å‘Šè­¦
            await self._alert_persistence_failure("workspace_info", str(e))
            raise WorkspaceInfoPersistenceError(
                f"Failed to save workspace info: {e}",
                workspace_id=self.workspace_info.id,
            )

    async def _initialize_llm_manager(self):
        """åˆå§‹åŒ– LLM ç®¡ç†å™¨ï¼ˆçŽ°åœ¨ä»Ž WorkspaceContext èŽ·å–ï¼‰

        â­ æ”¹åŠ¨ï¼šä¸å†åˆ›å»ºï¼Œç›´æŽ¥ä½¿ç”¨ WorkspaceContext ä¸­çš„
        """
        # LLM ç®¡ç†å™¨å·²ç»åœ¨ WorkspaceContext ä¸­åˆå§‹åŒ–
        # é€šè¿‡ @property llm_manager è‡ªåŠ¨èŽ·å–
        logger.debug("LLM manager provided by WorkspaceContext")

    async def _initialize_conversation_management(self):
        """åˆå§‹åŒ–å¯¹è¯ç®¡ç†"""
        # ConversationHistoryManager çŽ°åœ¨ä»Ž WorkspaceContext èŽ·å–
        logger.info("Initializing conversation management...")

        # å¦‚æžœæ²¡æœ‰å½“å‰å¯¹è¯ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
        if self.current_conversation is None:
            current_llm_config = self.llm_manager.get_current_config_name() if self.llm_manager else "glm"
            self.current_conversation = create_conversation(
                title="æ–°å¯¹è¯",
                agent_mode="orchestrator",
                llm_model=current_llm_config or "glm",
            )

        logger.info("Conversation management initialized successfully.")

    async def _load_configurations(self):
        """åŠ è½½æ‰€æœ‰é…ç½®æ–‡ä»¶"""
        logger.info("Loading configurations...")

        # åŠ è½½ç»Ÿä¸€å·¥ä½œåŒºé…ç½®ï¼ˆconfig.jsonï¼‰
        await self._load_workspace_config()

        # åŠ è½½æ’ä»¶é…ç½®ï¼ˆ.dawei/plugins/{plugin_id}.jsonï¼‰
        await self._load_plugins_config()

        # åŠ è½½å·¥ä½œåŒºè®¾ç½®ï¼ˆsettings.jsonï¼‰
        await self._load_settings()

        logger.info("Configurations loaded successfully.")

    async def _load_workspace_config(self):
        """åŠ è½½å·¥ä½œåŒºé…ç½®ï¼ˆconfig.jsonï¼‰åˆ° Pydantic æ¨¡åž‹"""
        config_file = self.workspace_path / ".dawei" / "config.json"

        if not config_file.exists():
            # ä½¿ç”¨é»˜è®¤é…ç½®
            from dawei.api.workspaces.config import DEFAULT_CONFIG

            config_dict = DEFAULT_CONFIG.copy()
            logger.info(f"Config file not found, using defaults: {config_file}")
        else:
            try:
                with config_file.open(encoding="utf-8") as f:
                    config_dict = json.load(f)
                logger.info(f"Loading config from: {config_file}")
            except (OSError, json.JSONDecodeError) as e:
                # Fast Fail: é…ç½®æ–‡ä»¶å­˜åœ¨ä½†æ— æ•ˆ
                from dawei.core.exceptions import ConfigurationError

                raise ConfigurationError(f"Invalid workspace config file {config_file}: {e}") from e

        # ä½¿ç”¨ Pydantic æ¨¡åž‹éªŒè¯å’ŒåŠ è½½
        from .models import WorkspaceConfig

        self.workspace_config = WorkspaceConfig.from_dict(config_dict)

        logger.info("Workspace config loaded successfully.")

    def get_config(self):
        """èŽ·å–å·¥ä½œåŒºé…ç½®ï¼ˆFast Fail å¦‚æžœæœªåŠ è½½ï¼‰

        Returns:
            WorkspaceConfig: å·¥ä½œåŒºé…ç½®å¯¹è±¡

        Raises:
            RuntimeError: å¦‚æžœé…ç½®æœªåŠ è½½ï¼ˆè°ƒç”¨ initialize() å‰è®¿é—®ï¼‰
        """
        if self.workspace_config is None:
            raise RuntimeError(f"Workspace config not loaded. Call initialize() first. Workspace: {self.absolute_path}")
        return self.workspace_config

    async def save_workspace_config(self):
        """ä¿å­˜å·¥ä½œåŒºé…ç½®åˆ° config.json"""
        if self.workspace_config is None:
            raise RuntimeError("No config to save")

        config_file = self.workspace_path / ".dawei" / "config.json"

        # ç¡®ä¿é…ç½®ç›®å½•å­˜åœ¨
        config_file.parent.mkdir(parents=True, exist_ok=True)

        # åºåˆ—åŒ–ä¸º JSON
        config_dict = self.workspace_config.model_dump_custom()

        with config_file.open("w", encoding="utf-8") as f:
            json.dump(config_dict, f, indent=2, ensure_ascii=False)

        logger.info(f"Workspace config saved: {config_file}")

    async def _load_settings(self):
        """åŠ è½½è®¾ç½®é…ç½®ï¼ˆåˆå¹¶å…¨å±€é…ç½®å’Œå·¥ä½œåŒºé…ç½®ï¼‰

        é…ç½®ç»§æ‰¿è§„åˆ™ï¼š
        1. å…¨å±€é…ç½®ï¼š~/.dawei/configs/settings.json
        2. å·¥ä½œåŒºé…ç½®ï¼š{workspace}/.dawei/settings.json
        3. å·¥ä½œåŒºé…ç½®è¦†ç›–å…¨å±€é…ç½®ï¼ˆç›¸åŒå­—æ®µï¼‰
        4. å·¥ä½œåŒºä¸å­˜åœ¨çš„å­—æ®µç»§æ‰¿å…¨å±€é…ç½®

        æ³¨æ„ï¼š
        - ç©ºå­—ç¬¦ä¸²ã€ç©ºåˆ—è¡¨ã€Falseã€0 ç­‰å‡å€¼ä¼šæ­£ç¡®è¦†ç›–å…¨å±€é…ç½®
        - æ˜¾å¼è®¾ç½®çš„å­—æ®µä¼šç»§æ‰¿å…¨å±€é»˜è®¤å€¼
        - ä¾‹å¦‚ï¼šå…¨å±€ config["allowedCommands"] = ["pnpm"]ï¼Œ
          å·¥ä½œåŒºä¸è®¾ç½®è¯¥å­—æ®µæ—¶ï¼Œä¼šç»§æ‰¿ ["pnpm"]
          å·¥ä½œåŒºè®¾ç½® "allowedCommands": [] æ—¶ï¼Œä¼šè¦†ç›–ä¸º []
        """
        # 1. å…ˆåŠ è½½å…¨å±€é…ç½®ä½œä¸ºåŸºç¡€
        global_settings_path = Path.home() / ".dawei" / "configs" / "settings.json"
        global_settings_dict = {}

        if global_settings_path.exists():
            try:
                with global_settings_path.open(encoding="utf-8") as f:
                    global_data = json.load(f)
                    global_settings_dict = global_data.get("globalSettings", {})
                    logger.info(f"Loaded global settings from {global_settings_path}")
            except (OSError, json.JSONDecodeError) as e:
                logger.warning(f"Failed to load global settings: {e}")

        # 2. åŠ è½½å·¥ä½œåŒºé…ç½®ï¼ˆè¦†ç›–å…¨å±€é…ç½®ï¼‰
        workspace_settings_dict = {}
        if self.settings_file.exists():
            try:
                with Path(self.settings_file).open(encoding="utf-8") as f:
                    config_data = json.load(f)
                    workspace_settings_dict = config_data.get("globalSettings", {})
                    logger.info(f"Loaded workspace settings from {self.settings_file}")
            except (OSError, json.JSONDecodeError) as e:
                logger.warning(f"Failed to load workspace settings: {e}")
        else:
            logger.info("Workspace settings file not found, using global settings")

        # 3. åˆå¹¶é…ç½®ï¼ˆå·¥ä½œåŒºé…ç½®è¦†ç›–å…¨å±€é…ç½®ï¼‰
        merged_settings = {**global_settings_dict, **workspace_settings_dict}

        # 4. åˆ›å»º WorkspaceSettings å¯¹è±¡
        self.workspace_settings = WorkspaceSettings.from_dict(merged_settings)

        # 5. è®°å½•é…ç½®æ¥æº
        if workspace_settings_dict:
            overridden_fields = set(workspace_settings_dict.keys()) & set(global_settings_dict.keys())
            if overridden_fields:
                logger.info(f"Workspace settings override global fields: {overridden_fields}")
            else:
                logger.info("Workspace settings only add new fields to global settings")

        logger.info("Workspace settings loaded successfully.")

    async def _save_settings(self, only_fields: set[str] | None = None):
        """ä¿å­˜è®¾ç½®é…ç½®åˆ° settings.json

        Args:
            only_fields: åªä¿å­˜æŒ‡å®šçš„å­—æ®µï¼ˆé©¼å³°å‘½åï¼Œå¦‚ {"httpProxy", "httpsProxy"}ï¼‰ï¼Œ
                        None è¡¨ç¤ºä¿å­˜æ‰€æœ‰å­—æ®µ
        """
        if self.workspace_settings is None:
            self.workspace_settings = WorkspaceSettings()

        # è¯»å–çŽ°æœ‰çš„ settings.jsonï¼ˆå¦‚æžœå­˜åœ¨ï¼‰
        existing_data = {}
        if self.settings_file.exists():
            try:
                with Path(self.settings_file).open(encoding="utf-8") as f:
                    existing_data = json.load(f)
            except (OSError, json.JSONDecodeError):
                pass

        # å­—æ®µåæ˜ å°„ï¼šPython å­—æ®µå -> JSON å­—æ®µå
        field_mapping = {
            "auto_approval_enabled": "autoApprovalEnabled",
            "always_allow_read_only": "alwaysAllowReadOnly",
            "always_allow_read_only_outside_workspace": "alwaysAllowReadOnlyOutsideWorkspace",
            "always_allow_write": "alwaysAllowWrite",
            "always_allow_write_outside_workspace": "alwaysAllowWriteOutsideWorkspace",
            "always_allow_write_protected": "alwaysAllowWriteProtected",
            "write_delay_ms": "writeDelayMs",
            "always_allow_browser": "browserToolEnabled",
            "always_approve_resubmit": "alwaysApproveResubmit",
            "request_delay_seconds": "requestDelaySeconds",
            "always_allow_mcp": "mcpEnabled",
            "always_allow_mode_switch": "alwaysAllowModeSwitch",
            "always_allow_subtasks": "alwaysAllowSubtasks",
            "always_allow_execute": "alwaysAllowExecute",
            "always_allow_followup_questions": "alwaysAllowFollowupQuestions",
            "followup_auto_approve_timeout_ms": "followupAutoApproveTimeoutMs",
            "always_allow_update_todo_list": "alwaysAllowUpdateTodoList",
            "allowed_commands": "allowedCommands",
            "denied_commands": "deniedCommands",
            "max_concurrent_file_reads": "maxConcurrentFileReads",
            "max_workspace_files": "maxWorkspaceFiles",
            "max_read_file_line": "maxReadFileLine",
            "max_image_file_size": "maxImageFileSize",
            "max_total_image_size": "maxTotalImageSize",
            "terminal_output_line_limit": "terminalOutputLineLimit",
            "terminal_output_character_limit": "terminalOutputCharacterLimit",
            "http_proxy": "httpProxy",
            "https_proxy": "httpsProxy",
            "no_proxy": "noProxy",
        }

        # å¢žé‡æ›´æ–°æˆ–å…¨é‡æ›´æ–°
        if only_fields:
            # å¢žé‡æ¨¡å¼ï¼šåªæ›´æ–°æŒ‡å®šçš„å­—æ®µ
            if "globalSettings" not in existing_data:
                existing_data["globalSettings"] = {}

            for py_field, json_field in field_mapping.items():
                if json_field in only_fields:
                    # æ›´æ–°æŒ‡å®šå­—æ®µ
                    value = getattr(self.workspace_settings, py_field)
                    existing_data["globalSettings"][json_field] = value

            logger.info(f"Workspace settings incremental update: {only_fields}")
        else:
            # å…¨é‡æ¨¡å¼ï¼šä¿å­˜æ‰€æœ‰å­—æ®µï¼ˆå‘åŽå…¼å®¹ï¼‰
            settings_dict = {
                json_field: getattr(self.workspace_settings, py_field)
                for py_field, json_field in field_mapping.items()
            }
            existing_data["globalSettings"] = settings_dict
            logger.info("Workspace settings full update")

        # ç¡®ä¿ settings ç›®å½•å­˜åœ¨
        self.settings_file.parent.mkdir(parents=True, exist_ok=True)

        # å†™å…¥æ–‡ä»¶
        with self.settings_file.open("w", encoding="utf-8") as f:
            json.dump(existing_data, f, indent=2, ensure_ascii=False)

        logger.info(f"Workspace settings saved: {self.settings_file}")

    async def _load_plugins_config(self):
        """åŠ è½½æ’ä»¶é…ç½®

        æ ¼å¼ï¼š.dawei/plugins/{plugin_id}.json
        æ¯ä¸ªæ’ä»¶ä¸€ä¸ªé…ç½®æ–‡ä»¶ï¼ŒåŒ…å« enabledã€activatedã€settings
        """
        plugins_dir = self.workspace_path / ".dawei" / "plugins"

        from .models import PluginInstanceConfig, PluginsConfig

        # ä»Ž .dawei/plugins/*.json åŠ è½½
        if plugins_dir.exists() and plugins_dir.is_dir():
            plugins_config_dict = {}

            for config_file in plugins_dir.glob("*.json"):
                # è·³è¿‡ config_schema.json ç­‰éžæ’ä»¶é…ç½®æ–‡ä»¶
                if config_file.name == "config_schema.json":
                    continue

                try:
                    plugin_id = config_file.stem
                    with config_file.open(encoding="utf-8") as f:
                        config_data = json.load(f)

                    plugins_config_dict[plugin_id] = PluginInstanceConfig.model_validate(config_data)
                    logger.debug(f"Loaded plugin config: {plugin_id}")
                except Exception as e:
                    logger.warning(f"Failed to load plugin config {config_file}: {e}")

            if plugins_config_dict:
                self.plugins_config = PluginsConfig(
                    plugins=plugins_config_dict,
                    max_plugins=50,
                    auto_discovery=True,
                    enabled=True,
                )
                logger.info(f"Loaded {len(plugins_config_dict)} plugins from {plugins_dir}")
                return

        # é»˜è®¤é…ç½®ï¼ˆæ— æ’ä»¶ï¼‰
        logger.info("No plugin configs found, using defaults")
        self.plugins_config = PluginsConfig()

    async def _save_plugins_config(self):
        """ä¿å­˜æ’ä»¶é…ç½®åˆ° .dawei/plugins/{plugin_id}.json"""
        if self.plugins_config is None:
            raise RuntimeError("No plugins config to save")

        plugins_dir = self.workspace_path / ".dawei" / "plugins"
        plugins_dir.mkdir(parents=True, exist_ok=True)

        # ä¸ºæ¯ä¸ªæ’ä»¶ä¿å­˜ç‹¬ç«‹çš„é…ç½®æ–‡ä»¶
        saved_count = 0
        for plugin_id, config in self.plugins_config.plugins.items():
            config_file = plugins_dir / f"{plugin_id}.json"
            try:
                with config_file.open("w", encoding="utf-8") as f:
                    json.dump(config.model_dump(), f, indent=2, ensure_ascii=False)
                saved_count += 1
                logger.debug(f"Saved plugin config: {plugin_id}")
            except Exception as e:
                logger.exception(f"Failed to save plugin config {plugin_id}: {e}")

        logger.info(f"Saved {saved_count} plugin configs to {plugins_dir}")
        """åˆå§‹åŒ–MCPå·¥å…·ç®¡ç†å™¨ï¼ˆçŽ°åœ¨ä»Ž WorkspaceContext èŽ·å–ï¼‰

        â­ æ”¹åŠ¨ï¼šä¸å†åˆ›å»ºï¼Œç›´æŽ¥ä½¿ç”¨ WorkspaceContext ä¸­çš„
        """
        # MCP å·¥å…·ç®¡ç†å™¨å·²ç»åœ¨ WorkspaceContext ä¸­åˆå§‹åŒ–
        # é€šè¿‡ @property mcp_tool_manager è‡ªåŠ¨èŽ·å–
        logger.debug("MCP tool manager provided by WorkspaceContext")

    async def _initialize_tools(self):
        """åˆå§‹åŒ–å·¥å…·ç®¡ç†å™¨ï¼ˆçŽ°åœ¨ä»Ž WorkspaceContext èŽ·å–ï¼‰

        â­ æ”¹åŠ¨ï¼šä¸å†åˆ›å»ºï¼Œç›´æŽ¥ä½¿ç”¨ WorkspaceContext ä¸­çš„
        """
        # å·¥å…·ç®¡ç†å™¨å·²ç»åœ¨ WorkspaceContext ä¸­åˆå§‹åŒ–
        # é€šè¿‡ @property tool_manager è‡ªåŠ¨èŽ·å–
        logger.debug("Tool manager provided by WorkspaceContext")

        # ðŸ”§ åˆå§‹åŒ–Skillså·¥å…· - ä¸‰çº§åŠ è½½æœºåˆ¶
        from pathlib import Path

        from dawei.tools.custom_tools.skills_tool import create_skills_tools

        def find_skills_roots() -> list[Path]:
            """æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½åŒ…å«skillsçš„æ ¹ç›®å½•
            è¿”å›žä¸¤ä¸ªçº§åˆ«çš„æ ¹ç›®å½•åˆ—è¡¨ï¼ˆworkspaceå’Œglobal userï¼‰

            æ–°çš„è·¯å¾„ç»“æž„ï¼š.dawei/skills/
            """
            roots = []
            ws_path = Path(self.absolute_path)

            # èŽ·å–å½“å‰modeï¼ˆç”¨äºŽmode-specific skillsï¼‰
            current_mode = None
            try:
                if hasattr(self, "mode") and self.mode:
                    current_mode = self.mode
                elif self.workspace_info and hasattr(self.workspace_info, "user_ui_context"):
                    current_mode = self.workspace_info.user_ui_context.current_mode
            except (AttributeError, TypeError) as mode_error:
                # mode èŽ·å–å¤±è´¥æ˜¯é¢„æœŸçš„ï¼Œä½¿ç”¨ None ä½œä¸ºé»˜è®¤å€¼
                logger.debug(f"Could not determine current mode: {mode_error}")
            except Exception as e:
                # æœªé¢„æœŸçš„é”™è¯¯åº”è¯¥è®°å½•
                logger.warning(f"Unexpected error getting current mode: {e}", exc_info=True)

            logger.debug(f"Current mode for skills: {current_mode}")

            # ===== Level 1: UserWorkspaceçº§åˆ« =====
            # 1.1 {workspace}/.dawei/skills/
            ws_dawei_configs = ws_path / ".dawei"
            ws_skills_dir = ws_dawei_configs / "skills"
            if ws_skills_dir.exists() and any(ws_skills_dir.iterdir()):
                logger.info("[Level 1: Workspace] Found .dawei/skills in workspace")
                roots.append(ws_path)

            # 1.2 {workspace}/.dawei/skills-{mode}/
            if current_mode:
                ws_mode_skills = ws_dawei_configs / f"skills-{current_mode}"
                if ws_mode_skills.exists() and any(ws_mode_skills.iterdir()):
                    logger.info(
                        f"[Level 1: Workspace] Found .dawei/skills-{current_mode} in workspace",
                    )
                    roots.append(ws_path)

            # ===== Level 2: Global Userçº§åˆ« =====
            # 2.1 {DAWEI_HOME}/skills/
            dawei_home = get_dawei_home()
            global_dawei_configs = dawei_home 
            global_skills_dir = global_dawei_configs / "skills"
            if global_skills_dir.exists() and any(global_skills_dir.iterdir()):
                logger.info("[Level 2: Global User] Found .dawei/skills in DAWEI_HOME")
                roots.append(dawei_home)

            # 2.2 {DAWEI_HOME}/skills-{mode}/
            if current_mode:
                global_mode_skills = global_dawei_configs / f"skills-{current_mode}"
                if global_mode_skills.exists() and any(global_mode_skills.iterdir()):
                    logger.info(
                        f"[Level 2: Global User] Found .dawei/skills-{current_mode} in DAWEI_HOME",
                    )
                    roots.append(dawei_home)

            logger.info(f"Skills discovery: found {len(roots)} root(s) with skills")
            return roots

        # æŸ¥æ‰¾æ‰€æœ‰skillsæ ¹ç›®å½•
        skills_roots = find_skills_roots()

        # åˆ›å»ºskillså·¥å…· - ä¼ å…¥æ‰€æœ‰æ‰¾åˆ°çš„æ ¹ç›®å½•
        self._skills_tools = create_skills_tools(
            skills_roots=skills_roots,  # æ‰€æœ‰åŒ…å«.daweiçš„æ ¹ç›®å½•
            current_mode=None,  # modeå·²ç»åœ¨æŸ¥æ‰¾æ—¶å¤„ç†
        )

        logger.info(
            f"âœ“ Created {len(self._skills_tools)} skills tools from {len(skills_roots)} root(s)",
        )

        # è®°å½•å†…ç½®æä¾›è€…ä¿¡æ¯
        providers_info = self.tool_manager.get_builtin_providers_info()
        logger.info("Builtin providers info:")
        for provider_name, info in providers_info.items():
            logger.info(f"  {provider_name}: {info['count']} tools - {info['description']}")

        # è®°å½•å·¥å…·è¦†ç›–ä¿¡æ¯
        override_info = self.tool_manager.get_all_override_info()
        if override_info:
            logger.info(f"Found {len(override_info)} overridden tools")
            for info in override_info[:3]:  # åªè®°å½•å‰3ä¸ª
                logger.info(
                    f"  - {info['tool_name']}: {info['active_source']} overrides other sources",
                )

        # åˆå§‹åŒ–å…è®¸çš„å·¥å…·åç§°
        await self._update_allowed_tools()

    async def _update_allowed_tools(self):
        """æ›´æ–°å…è®¸çš„å·¥å…·åˆ—è¡¨ - ç”± ToolManager ç»Ÿä¸€ç®¡ç†"""
        if self.tool_manager:
            # ä»Ž ToolManager èŽ·å–æœ€æ–°å·¥å…·åˆ—è¡¨
            all_tools = self.tool_manager.load_tools()
            # åº”ç”¨å·¥ä½œåŒºè¿‡æ»¤
            allowed_tool_names = self._get_filtered_tool_names(all_tools)
            logger.info(f"Allowed tools updated: {len(allowed_tool_names)} out of {len(all_tools)}")
        else:
            logger.warning("ToolManager not initialized, cannot update allowed tools")

    # å¯¹è¯ç®¡ç†æ–¹æ³•
    async def new_conversation(
        self,
        title: str = "æ–°å¯¹è¯",
        agent_mode: str = "orchestrator",
    ) -> Conversation:
        """åˆ›å»ºæ–°å¯¹è¯å¹¶è®¾ç½®ä¸ºå½“å‰å¯¹è¯

        Args:
            title: å¯¹è¯æ ‡é¢˜
            agent_mode: ä»£ç†æ¨¡å¼

        Returns:
            Conversation: æ–°åˆ›å»ºçš„å¯¹è¯

        """
        # ä¿å­˜å½“å‰å¯¹è¯åˆ°åŽ†å²ï¼ˆå¦‚æžœæœ‰æ¶ˆæ¯ï¼‰
        if self.current_conversation and self.current_conversation.message_count > 0:
            await self.save_current_conversation()

        # åˆ›å»ºæ–°å¯¹è¯
        current_llm_config = self.llm_manager.get_current_config_name() if self.llm_manager else "glm"
        self.current_conversation = create_conversation(
            title=title,
            agent_mode=agent_mode,
            llm_model=current_llm_config or "glm",
        )

        logger.info(f"Created new conversation: {title}")
        return self.current_conversation

    async def save_current_conversation(self) -> bool:
        """ä¿å­˜å½“å‰å¯¹è¯åˆ°åŽ†å² (ä½¿ç”¨æŒä¹…åŒ–ç®¡ç†å™¨)

        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ

        Raises:
            ConversationPersistenceError: å½“å¯¹è¯æŒä¹…åŒ–å¤±è´¥æ—¶
            PersistenceError: å½“æŒä¹…åŒ–ç®¡ç†å™¨ä¸å¯ç”¨æ—¶

        """
        logger.info("[SAVE_CONVERSATION] Starting save for conversation")

        if not self.current_conversation:
            raise ConversationPersistenceError(
                "current_conversation is None",
                conversation_id="unknown",
            )

        if not self.conversation_history_manager:
            raise ConversationPersistenceError(
                "conversation_history_manager is None",
                conversation_id="unknown",
            )

        logger.info(
            f"[SAVE_CONVERSATION] Conversation details: id={self.current_conversation.id}, message_count={self.current_conversation.message_count}",
        )

        # é¦–å…ˆå°è¯•ä½¿ç”¨æŒä¹…åŒ–ç®¡ç†å™¨ä¿å­˜
        if self.persistence_manager:
            # å°†å¯¹è¯è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            conversation_dict = self._conversation_to_dict(self.current_conversation)

            success = await self.persistence_manager.save_conversation(
                self.current_conversation.id,
                conversation_dict,
            )

            if success:
                logger.info(
                    f"[SAVE_CONVERSATION] Successfully saved conversation via persistence manager: {self.current_conversation.id}",
                )
                return True
            logger.warning(
                "[SAVE_CONVERSATION] Persistence manager save failed, falling back to conversation_history_manager",
            )

        # å›žé€€åˆ°å¯¹è¯åŽ†å²ç®¡ç†å™¨
        success = await self.conversation_history_manager.save_by_id(
            self.current_conversation.id,
            self.current_conversation,
        )

        if success:
            logger.info(
                f"[SAVE_CONVERSATION] Successfully saved conversation via history manager: {self.current_conversation.id}",
            )
        else:
            logger.error(
                f"[SAVE_CONVERSATION] Failed to save conversation: {self.current_conversation.id}",
            )
            # å‘é€æŒä¹…åŒ–å¤±è´¥å‘Šè­¦
            await self._alert_persistence_failure(
                "conversation",
                f"Failed to save conversation {self.current_conversation.id}",
                conversation_id=self.current_conversation.id,
            )

        return success

    def _conversation_to_dict(self, conversation: Conversation) -> dict[str, Any]:
        """å°†å¯¹è¯å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        # å¤„ç†æ—¶é—´æˆ³ - ç¡®ä¿æ˜¯å­—ç¬¦ä¸²æ ¼å¼
        created_at = conversation.created_at
        if isinstance(created_at, datetime):
            created_at = created_at.isoformat()
        elif created_at is None:
            created_at = datetime.now(UTC).isoformat()

        updated_at = conversation.updated_at
        if isinstance(updated_at, datetime):
            updated_at = updated_at.isoformat()
        elif updated_at is None:
            updated_at = datetime.now(UTC).isoformat()

        # æ­£ç¡®åºåˆ—åŒ–æ¶ˆæ¯ - ä½¿ç”¨ to_dict() æ–¹æ³•ç¡®ä¿ datetime æ­£ç¡®è½¬æ¢
        messages_data = []
        for msg in conversation.messages:
            # ä½¿ç”¨ to_dict() æ–¹æ³•ï¼Œè¿™æ˜¯æœ€å¯é çš„åºåˆ—åŒ–æ–¹å¼
            # to_dict() ä¼šè°ƒç”¨ to_openai_format()ï¼Œæ­£ç¡®å¤„ç† datetime
            if hasattr(msg, "to_dict") and callable(msg.to_dict):
                msg_dict = msg.to_dict()
            # å›žé€€åˆ° model_dump/dict
            elif hasattr(msg, "model_dump"):
                msg_dict = msg.model_dump(exclude_none=True)
            elif hasattr(msg, "dict"):
                msg_dict = msg.dict(exclude_none=True)
            else:
                msg_dict = {}

            # ç¡®ä¿ content å­—æ®µæ˜¯å­—ç¬¦ä¸²æ ¼å¼(å¤„ç†OpenAIæ ¼å¼çš„contentå¯¹è±¡)
            if "content" in msg_dict and isinstance(msg_dict["content"], dict):
                # OpenAIæ ¼å¼: {"type": "text", "text": "..."}
                if msg_dict["content"].get("type") == "text":
                    msg_dict["content"] = msg_dict["content"].get("text", "")
                else:
                    # å…¶ä»–ç±»åž‹,è½¬ä¸ºJSONå­—ç¬¦ä¸²
                    import json

                    msg_dict["content"] = json.dumps(msg_dict["content"])

            messages_data.append(msg_dict)

        return {
            "id": conversation.id,
            "title": conversation.title,
            "agent_mode": conversation.agent_mode,
            "llm_model": conversation.llm_model,
            "created_at": created_at,
            "updated_at": updated_at,
            "messages": messages_data,
            "message_count": conversation.message_count,
        }

    async def load_conversation(self, conversation_id: str) -> bool:
        """åŠ è½½æŒ‡å®šå¯¹è¯ä½œä¸ºå½“å‰å¯¹è¯

        Args:
            conversation_id: å¯¹è¯ID

        Returns:
            bool: åŠ è½½æ˜¯å¦æˆåŠŸ

        Raises:
            ConversationPersistenceError: å½“å¯¹è¯åŽ†å²ç®¡ç†å™¨ä¸å¯ç”¨æ—¶
            ConversationPersistenceError: å½“å¯¹è¯åŠ è½½å¤±è´¥æ—¶

        """
        if not self.conversation_history_manager:
            raise ConversationPersistenceError(
                "conversation_history_manager is None",
                conversation_id=conversation_id,
            )

        # å…ˆä¿å­˜å½“å‰å¯¹è¯
        if self.current_conversation and self.current_conversation.message_count > 0:
            await self.save_current_conversation()

        # åŠ è½½æŒ‡å®šå¯¹è¯
        conversation = await self.conversation_history_manager.get_by_id(conversation_id)
        if conversation:
            self.current_conversation = conversation
            logger.info(f"Loaded conversation: {conversation_id}")
            return True
        raise ConversationPersistenceError(
            f"Conversation not found: {conversation_id}",
            conversation_id=conversation_id,
        )

    async def delete_conversation(self, conversation_id: str) -> bool:
        """åˆ é™¤æŒ‡å®šå¯¹è¯

        Args:
            conversation_id: å¯¹è¯ID

        Returns:
            bool: åˆ é™¤æ˜¯å¦æˆåŠŸ

        Raises:
            ConversationPersistenceError: å½“å¯¹è¯åŽ†å²ç®¡ç†å™¨ä¸å¯ç”¨æ—¶
            ConversationPersistenceError: å½“å¯¹è¯åˆ é™¤å¤±è´¥æ—¶

        """
        if not self.conversation_history_manager:
            raise ConversationPersistenceError(
                "conversation_history_manager is None",
                conversation_id=conversation_id,
            )

        success = await self.conversation_history_manager.delete_by_id(conversation_id)
        if success:
            # å¦‚æžœåˆ é™¤çš„æ˜¯å½“å‰å¯¹è¯ï¼Œåˆ›å»ºæ–°å¯¹è¯
            if self.current_conversation and self.current_conversation.id == conversation_id:
                current_llm_config = self.llm_manager.get_current_config_name() if self.llm_manager else "glm"
                self.current_conversation = create_conversation(
                    title="æ–°å¯¹è¯",
                    agent_mode="orchestrator",  # ä½¿ç”¨orchestratorä½œä¸ºé»˜è®¤æ¨¡å¼
                    llm_model=current_llm_config or "glm",
                )
            logger.info(f"Deleted conversation: {conversation_id}")
        else:
            raise ConversationPersistenceError(
                f"Failed to delete conversation: {conversation_id}",
                conversation_id=conversation_id,
            )

        return success

    async def get_conversation_list(self) -> list[Conversation]:
        """èŽ·å–å¯¹è¯åŽ†å²åˆ—è¡¨

        Returns:
            List[Conversation]: å¯¹è¯åˆ—è¡¨

        Raises:
            ConversationPersistenceError: å½“å¯¹è¯åŽ†å²ç®¡ç†å™¨ä¸å¯ç”¨æ—¶

        """
        if not self.conversation_history_manager:
            raise ConversationPersistenceError(
                "conversation_history_manager is None",
                conversation_id="unknown",
            )

        return await self.conversation_history_manager.list_all()

    async def search_conversations(
        self,
        query: str,
        search_in_content: bool = False,
    ) -> list[Conversation]:
        """æœç´¢å¯¹è¯

        Args:
            query: æœç´¢å…³é”®è¯
            search_in_content: æ˜¯å¦åœ¨æ¶ˆæ¯å†…å®¹ä¸­æœç´¢

        Returns:
            List[Conversation]: åŒ¹é…çš„å¯¹è¯åˆ—è¡¨

        Raises:
            ConversationPersistenceError: å½“å¯¹è¯åŽ†å²ç®¡ç†å™¨ä¸å¯ç”¨æ—¶

        """
        if not self.conversation_history_manager:
            raise ConversationPersistenceError(
                "conversation_history_manager is None",
                conversation_id="unknown",
            )

        return await self.conversation_history_manager.search_conversations(
            query,
            search_in_content,
        )

    async def restore(self, conversation_id: str | None = None) -> bool:
        """æ ¹æ® conversation_id åŠ è½½æˆ–è€…æ–°å»º current_conversation

        Args:
            conversation_id: å¯¹è¯IDï¼Œå¦‚æžœä¸º None åˆ™åˆ›å»ºæ–°å¯¹è¯

        Returns:
            bool: æ“ä½œæ˜¯å¦æˆåŠŸ

        Raises:
            ConversationPersistenceError: å½“å¯¹è¯åŠ è½½å¤±è´¥æ—¶
            WorkspaceInfoPersistenceError: å½“å·¥ä½œåŒºä¿¡æ¯ä¸å­˜åœ¨æ—¶
            PersistenceError: å½“å…¶ä»–æŒä¹…åŒ–é”™è¯¯å‘ç”Ÿæ—¶

        """
        if conversation_id:
            # å°è¯•åŠ è½½æŒ‡å®šIDçš„å¯¹è¯
            success = await self.load_conversation(conversation_id)
            if success:
                # æ›´æ–° user_ui_context ä¸­çš„ conversation_id
                if self.workspace_info and self.workspace_info.user_ui_context:
                    self.workspace_info.user_ui_context.conversation_id = conversation_id
                self.logger.info(f"Successfully restored conversation: {conversation_id}")
                return True
            self.logger.warning(
                f"Failed to load conversation: {conversation_id}, creating new conversation",
            )

        # å¦‚æžœæ²¡æœ‰æä¾› conversation_id æˆ–åŠ è½½å¤±è´¥ï¼Œåˆ›å»ºæ–°å¯¹è¯
        current_llm_config = self.llm_manager.get_current_config_name() if self.llm_manager else "glm"
        self.current_conversation = create_conversation(
            title="æ–°å¯¹è¯",
            agent_mode="orchestrator",  # é»˜è®¤ä½¿ç”¨orchestratoræ¨¡å¼
            llm_model=current_llm_config or "glm",
        )

        # æ›´æ–° user_ui_context ä¸­çš„ conversation_id
        if self.workspace_info and self.workspace_info.user_ui_context:
            self.workspace_info.user_ui_context.conversation_id = self.current_conversation.id

        self.logger.info(f"Created new conversation: {self.current_conversation.id}")
        return True

    # é…ç½®ç®¡ç†æ–¹æ³• - å§”æ‰˜ç»™ LLMProvider
    def get_current_llm_config(self) -> LLMConfig | None:
        """èŽ·å–å½“å‰LLMé…ç½®"""
        if not self.llm_manager:
            return None
        provider_config = self.llm_manager.get_current_config()
        return provider_config.config if provider_config else None

    def set_current_llm_config(self, config_id: str) -> bool:
        """è®¾ç½®å½“å‰LLMé…ç½®"""
        if not self.llm_manager:
            logger.error("LLMProvider not initialized")
            return False

        success = self.llm_manager.set_current_config(config_id)

        # æ›´æ–°å½“å‰å¯¹è¯çš„LLMæ¨¡åž‹
        if success and self.current_conversation:
            self.current_conversation.llm_model = config_id

        return success

    def get_all_llm_configs(self) -> dict[str, LLMConfig]:
        """èŽ·å–æ‰€æœ‰LLMé…ç½®"""
        if not self.llm_manager:
            return {}

        all_configs = self.llm_manager.get_all_configs()
        return {name: config.config for name, config in all_configs.items()}

    def get_llm_config(self, config_name: str) -> LLMConfig | None:
        """èŽ·å–æŒ‡å®šåç§°çš„LLMé…ç½®"""
        if not self.llm_manager:
            return None

        provider_config = self.llm_manager.get_config(config_name)
        return provider_config.config if provider_config else None

    def get_mode_llm_config(self, mode: str) -> LLMConfig | None:
        """èŽ·å–æ¨¡å¼ç‰¹å®šçš„LLMé…ç½®"""
        if not self.llm_manager:
            return None

        provider_config = self.llm_manager.get_mode_config(mode)
        return provider_config.config if provider_config else None

    def set_mode_llm_config(self, mode: str, config_name: str) -> bool:
        """è®¾ç½®æ¨¡å¼ç‰¹å®šçš„LLMé…ç½®"""
        if not self.llm_manager:
            logger.error("LLMProvider not initialized")
            return False

        return self.llm_manager.set_mode_config(mode, config_name)

    def get_workspace_info(self) -> WorkspaceInfo | None:
        """èŽ·å–å·¥ä½œåŒºä¿¡æ¯"""
        return self.workspace_info

    async def update_workspace_info(self, **kwargs) -> bool:
        """æ›´æ–°å·¥ä½œåŒºä¿¡æ¯

        Args:
            **kwargs: è¦æ›´æ–°çš„å­—æ®µ

        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ

        """
        if not self.workspace_info:
            return False

        for key, value in kwargs.items():
            if hasattr(self.workspace_info, key):
                setattr(self.workspace_info, key, value)

        await self._save_workspace_info()
        logger.info("Workspace info updated successfully.")
        return True

    @property
    def allowed_tools(self) -> list[dict[str, Any]]:
        """èŽ·å–å…è®¸çš„å·¥å…·åˆ—è¡¨ - ç”± ToolManager ç»Ÿä¸€ç®¡ç†"""
        if self.tool_manager:
            # ä»Ž ToolManager èŽ·å–æœ€æ–°æ•°æ®å¹¶åº”ç”¨å·¥ä½œåŒºè¿‡æ»¤
            all_tools = self.tool_manager.load_tools()
            allowed_tool_names = self._get_filtered_tool_names(all_tools)
            tools = [tool for tool in all_tools if tool["name"] in allowed_tool_names]

            # ðŸ”§ æ·»åŠ skillså·¥å…·
            if self._skills_tools:
                for skill_tool in self._skills_tools:
                    tools.append(
                        {
                            "name": skill_tool.name,
                            "description": skill_tool.description,
                            "original_tool": skill_tool,  # ToolExecutorä¼šä½¿ç”¨è¿™ä¸ªå­—æ®µ
                            "category": "skills",
                            "enabled": True,
                        },
                    )

            return tools
        return []

    def _get_filtered_tool_names(self, tools: list[dict[str, Any]]) -> set[str]:
        """æ ¹æ®å·¥ä½œåŒºè®¾ç½®è¿‡æ»¤å·¥å…·åç§° - ä½¿ç”¨ ToolManager çš„ç»Ÿä¸€æ–¹æ³•"""
        if self.tool_manager:
            return self.tool_manager.get_filtered_tool_names(tools, self.workspace_settings)
        # å¦‚æžœ ToolManager ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºæœ¬è¿‡æ»¤é€»è¾‘
        if not self.workspace_settings:
            return {tool["name"] for tool in tools}

        allowed_tools = set()

        for tool in tools:
            tool_name = tool["name"]

            # åŸºæœ¬å·¥å…·æ€»æ˜¯å…è®¸çš„
            if tool_name in [
                "read_file",
                "write_to_file",
                "list_files",
                "search_files",
            ]:
                allowed_tools.add(tool_name)
                continue

            # MCPå·¥å…·éœ€è¦æ£€æŸ¥è®¾ç½®
            if tool_name.startswith(("mcp_", "use_mcp_")):
                if self.workspace_settings.always_allow_mcp:
                    allowed_tools.add(tool_name)
                continue

            # æµè§ˆå™¨å·¥å…·éœ€è¦æ£€æŸ¥è®¾ç½®
            if "browser" in tool_name.lower() or "chrome" in tool_name.lower():
                if self.workspace_settings.always_allow_browser:
                    allowed_tools.add(tool_name)
                continue

            # é»˜è®¤å…è®¸å…¶ä»–å·¥å…·
            allowed_tools.add(tool_name)

        return allowed_tools

    def get_tool_config(self, tool_name: str):
        """èŽ·å–ç‰¹å®šå·¥å…·çš„é…ç½®"""
        if self.tool_manager:
            return self.tool_manager.get_tool_config(tool_name)
        return None

    def is_tool_enabled(self, tool_name: str) -> bool:
        """æ£€æŸ¥å·¥å…·æ˜¯å¦å¯ç”¨"""
        if self.tool_manager:
            return self.tool_manager.is_tool_enabled(tool_name)
        return False

    def enable_tool(self, tool_name: str) -> bool:
        """å¯ç”¨å·¥å…· - ç”± ToolManager ç»Ÿä¸€ç®¡ç†"""
        if self.tool_manager:
            success = self.tool_manager.enable_tool(tool_name)
            if success:
                logger.info(f"Tool '{tool_name}' enabled successfully")
            return success
        return False

    def disable_tool(self, tool_name: str) -> bool:
        """ç¦ç”¨å·¥å…· - ç”± ToolManager ç»Ÿä¸€ç®¡ç†"""
        if self.tool_manager:
            success = self.tool_manager.disable_tool(tool_name)
            if success:
                logger.info(f"Tool '{tool_name}' disabled successfully")
            return success
        return False

    def get_tools_by_category(self, category: str) -> list[dict[str, Any]]:
        """æŒ‰ç±»åˆ«èŽ·å–å·¥å…·"""
        if self.tool_manager:
            tool_configs = self.tool_manager.get_tools_by_category(category)
            return [config.to_dict() for config in tool_configs]
        return []

    def get_mode_available_tools(self, mode: str) -> dict[str, Any]:
        """èŽ·å–æŒ‡å®šæ¨¡å¼ä¸‹å¯ç”¨çš„å·¥å…·

        Args:
            mode: æ¨¡å¼åç§°

        Returns:
            Dict[str, Any]: è¿‡æ»¤åŽçš„å·¥å…·å­—å…¸

        """
        # æ·»åŠ è¯Šæ–­æ—¥å¿—
        logger.debug(f"get_mode_available_tools called for mode: {mode}")
        logger.debug(f"tool_manager is None: {self.tool_manager is None}")
        logger.debug(f"mode_manager is None: {self.mode_manager is None}")
        logger.debug(f"UserWorkspace initialized: {self._initialized}")
        logger.debug(f"UserWorkspace loaded: {self._loaded}")

        # æ£€æŸ¥åˆå§‹åŒ–çŠ¶æ€
        if not self._initialized:
            logger.warning(
                f"UserWorkspace not initialized when get_mode_available_tools called for mode: {mode}",
            )
            # å°è¯•åŒæ­¥åˆå§‹åŒ–å…³é”®ç»„ä»¶
            try:
                if self.tool_manager is None:
                    logger.info("Attempting to initialize tool_manager synchronously")
                    from dawei.tools.tool_manager import ToolManager

                    self.tool_manager = ToolManager(workspace_path=self.absolute_path)
                    logger.info(
                        f"ToolManager created synchronously: {self.tool_manager is not None}",
                    )
            except Exception:
                logger.exception("Failed to initialize tool_manager synchronously: ")

        # èŽ·å–æ‰€æœ‰å·¥å…·
        if self.tool_manager is None:
            logger.error("tool_manager is None, returning empty tools list")
            return {
                "tools": [],
                "mode": mode,
                "total_count": 0,
                "mode_filtered_count": 0,
                "final_count": 0,
                "workspace_settings_applied": False,
                "error": "tool_manager not initialized",
            }

        all_tools = self.tool_manager.load_tools()
        logger.debug(f"Loaded {len(all_tools)} tools from tool_manager")

        # èŽ·å–æ¨¡å¼é…ç½®
        mode_info = self.mode_manager.get_mode_info(mode)
        logger.debug(f"Mode info for {mode}: {mode_info}")

        # æ ¹æ®æ¨¡å¼è¿‡æ»¤å·¥å…·
        mode_filtered_tools = self._filter_tools_by_mode(all_tools, mode_info)
        logger.debug(f"Mode filtered tools count: {len(mode_filtered_tools)}")

        # åº”ç”¨å·¥ä½œåŒºè®¾ç½®è¿‡æ»¤
        allowed_tool_names = self._get_filtered_tool_names(mode_filtered_tools)
        final_tools = [tool for tool in mode_filtered_tools if tool["name"] in allowed_tool_names]
        logger.debug(f"Final tools count: {len(final_tools)}")

        # è¿”å›žè¿‡æ»¤åŽçš„å·¥å…·å­—å…¸
        return {
            "tools": final_tools,
            "mode": mode,
            "total_count": len(all_tools),
            "mode_filtered_count": len(mode_filtered_tools),
            "final_count": len(final_tools),
            "workspace_settings_applied": True,
        }

    def _filter_tools_by_mode(
        self,
        tools: list[dict[str, Any]],
        mode_info: dict[str, Any],
    ) -> list[dict[str, Any]]:
        """æ ¹æ®æ¨¡å¼é…ç½®è¿‡æ»¤å·¥å…·

        Args:
            tools: æ‰€æœ‰å·¥å…·åˆ—è¡¨
            mode_info: æ¨¡å¼ä¿¡æ¯

        Returns:
            List[Dict[str, Any]]: è¿‡æ»¤åŽçš„å·¥å…·åˆ—è¡¨

        Raises:
            ValueError: å½“å·¥å…·ç®¡ç†å™¨ä¸å¯ç”¨æ—¶
            AttributeError: å½“æ¨¡å¼ä¿¡æ¯æ ¼å¼ä¸æ­£ç¡®æ—¶

        """
        if not mode_info:
            logger.debug("No mode_info provided, returning all tools")
            return tools

        # èŽ·å–æ¨¡å¼é…ç½®ä¸­çš„å·¥å…·åå¥½å’Œçº¦æŸ
        getattr(mode_info, "tool_preferences", {})
        getattr(mode_info, "constraints", [])
        groups = getattr(mode_info, "groups", [])
        filtered_tools = []

        # æ·»åŠ è¯Šæ–­æ—¥å¿—
        logger.debug(f"Filtering tools by mode - groups: {groups}")
        logger.debug(f"tool_manager is None: {self.tool_manager is None}")

        if self.tool_manager is None:
            raise ValueError("tool_manager is None, cannot get_available_tools_with_groups")

        mode_tools = self.tool_manager.get_available_tools_with_groups(groups)
        logger.debug(f"Mode tools from get_available_tools_with_groups: {mode_tools}")

        for tool in tools:
            tool_name = tool.get("name", "")
            if tool_name in mode_tools:
                filtered_tools.append(tool)

        logger.debug(f"Filtered {len(tools)} tools to {len(filtered_tools)} for mode")
        return filtered_tools

    def get_tool_statistics(self) -> dict[str, Any]:
        """èŽ·å–å·¥å…·ç»Ÿè®¡ä¿¡æ¯"""
        if self.tool_manager:
            stats = self.tool_manager.get_tool_statistics()

            # æ·»åŠ å·¥ä½œåŒºç‰¹å®šçš„ç»Ÿè®¡ä¿¡æ¯
            all_tools = self.tool_manager.load_tools()
            allowed_tool_names = self._get_filtered_tool_names(all_tools)
            stats["workspace_specific"] = {
                "available_tools_count": len(all_tools),
                "allowed_tools_count": len(allowed_tool_names),
                "workspace_path": self.absolute_path,
            }

            return stats
        return {}

    def reload_tool_configs(self):
        """é‡æ–°åŠ è½½å·¥å…·é…ç½® - ç”± ToolManager ç»Ÿä¸€ç®¡ç†"""
        if self.tool_manager:
            # é‡æ–°åŠ è½½æ‰€æœ‰é…ç½®
            self.tool_manager.reload_configs()

            # è®°å½•é‡æ–°åŠ è½½åŽçš„ç»Ÿè®¡ä¿¡æ¯
            stats = self.tool_manager.get_tool_statistics()
            logger.info(
                f"Tool configurations reloaded: {stats['total_tools']} total, {stats['overridden_tools']} overridden",
            )

            # æ³¨æ„ï¼šè¿™é‡Œä¸èƒ½ä½¿ç”¨ awaitï¼Œå› ä¸ºè¿™æ˜¯åŒæ­¥æ–¹æ³•
            # è°ƒç”¨è€…éœ€è¦åœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­å¤„ç† _update_allowed_tools()
        logger.info("Tool configurations reloaded")

    def get_tool_sources(self, tool_name: str) -> dict[str, bool]:
        """èŽ·å–å·¥å…·é…ç½®æ¥æºä¿¡æ¯"""
        if self.tool_manager:
            return self.tool_manager.get_tool_sources(tool_name)
        return {}

    # MCP ç®¡ç†æ–¹æ³• - å§”æ‰˜ç»™ MCPToolManager
    def get_mcp_config(self, server_name: str) -> MCPConfig | None:
        """èŽ·å–æŒ‡å®šæœåŠ¡å™¨çš„MCPé…ç½®"""
        if self.mcp_tool_manager:
            return self.mcp_tool_manager.get_config(server_name)
        return None

    def get_all_mcp_configs(self) -> dict[str, MCPConfig]:
        """èŽ·å–æ‰€æœ‰MCPé…ç½®"""
        if self.mcp_tool_manager:
            return self.mcp_tool_manager.get_all_configs()
        return {}

    def get_mcp_server_info(self, server_name: str):
        """èŽ·å–MCPæœåŠ¡å™¨ä¿¡æ¯"""
        if self.mcp_tool_manager:
            return self.mcp_tool_manager.get_server_info(server_name)
        return None

    def get_all_mcp_servers(self) -> dict[str, Any]:
        """èŽ·å–æ‰€æœ‰MCPæœåŠ¡å™¨ä¿¡æ¯"""
        if self.mcp_tool_manager:
            return self.mcp_tool_manager.get_all_servers()
        return {}

    def get_mcp_config_sources(self, server_name: str) -> dict[str, bool]:
        """èŽ·å–MCPé…ç½®æ¥æºä¿¡æ¯"""
        if self.mcp_tool_manager:
            return self.mcp_tool_manager.get_config_sources(server_name)
        return {}

    def get_mcp_statistics(self) -> dict[str, Any]:
        """èŽ·å–MCPç»Ÿè®¡ä¿¡æ¯"""
        if self.mcp_tool_manager:
            return self.mcp_tool_manager.get_statistics()
        return {}

    async def connect_mcp_server(self, server_name: str) -> bool:
        """è¿žæŽ¥MCPæœåŠ¡å™¨"""
        if self.mcp_tool_manager:
            return await self.mcp_tool_manager.connect_server(server_name)
        return False

    async def disconnect_mcp_server(self, server_name: str) -> bool:
        """æ–­å¼€MCPæœåŠ¡å™¨è¿žæŽ¥"""
        if self.mcp_tool_manager:
            return await self.mcp_tool_manager.disconnect_server(server_name)
        return False

    async def connect_all_mcp_servers(self) -> dict[str, bool]:
        """è¿žæŽ¥æ‰€æœ‰MCPæœåŠ¡å™¨"""
        if self.mcp_tool_manager:
            return await self.mcp_tool_manager.connect_all_servers()
        return {}

    async def disconnect_all_mcp_servers(self) -> dict[str, bool]:
        """æ–­å¼€æ‰€æœ‰MCPæœåŠ¡å™¨è¿žæŽ¥"""
        if self.mcp_tool_manager:
            return await self.mcp_tool_manager.disconnect_all_servers()
        return {}

    def reload_mcp_configs(self):
        """é‡æ–°åŠ è½½MCPé…ç½®"""
        if self.mcp_tool_manager:
            self.mcp_tool_manager.reload_configs()
            logger.info("MCP configurations reloaded")

    def is_path_allowed(self, path: str) -> bool:
        """æ£€æŸ¥è·¯å¾„æ˜¯å¦å…è®¸è®¿é—®"""
        # SUPER MODE: Allow all paths
        if is_super_mode_enabled():
            log_security_bypass("is_path_allowed", f"path={path}")
            return True

        # å¦‚æžœè·¯å¾„å·²ç»æ˜¯ç»å¯¹è·¯å¾„ï¼Œç›´æŽ¥è§£æžï¼›å¦åˆ™ä¸Ž workspace_path æ‹¼æŽ¥
        input_path = Path(path)
        abs_path = input_path.resolve() if input_path.is_absolute() else (Path(self.workspace_path) / input_path).resolve()

        logger.debug(
            f"is_path_allowed: input='{path}', workspace='{self.workspace_path}', resolved='{abs_path}'",
        )

        try:
            relative = abs_path.relative_to(self.workspace_path)
            logger.debug(f"is_path_allowed: path is within workspace, relative path='{relative}'")
            return True
        except ValueError:
            logger.warning(
                f"is_path_allowed: path '{abs_path}' is not within workspace '{self.workspace_path}'",
            )
            if self.workspace_settings:
                allowed = self.workspace_settings.always_allow_read_only_outside_workspace
                logger.debug(f"is_path_allowed: always_allow_read_only_outside_workspace={allowed}")
                return allowed
            return False

    def ensure_path_in_workspace(self, path: str) -> str:
        """ç¡®ä¿è·¯å¾„åœ¨å·¥ä½œåŒºå†…"""
        path = path.strip(".").strip()
        # å¦‚æžœè·¯å¾„å·²ç»æ˜¯ç»å¯¹è·¯å¾„ï¼Œç›´æŽ¥è§£æžï¼›å¦åˆ™ä¸Ž workspace_path æ‹¼æŽ¥
        input_path = Path(path)
        abs_path = input_path.resolve() if input_path.is_absolute() else (Path(self.workspace_path) / input_path).resolve()
        return str(abs_path)

    def create_task_context(self, cwd: str | None = None) -> TaskContext:
        """åˆ›å»ºä»»åŠ¡ä¸Šä¸‹æ–‡"""
        if cwd is None:
            cwd = str(self.workspace_path)

        if not self.is_path_allowed(cwd):
            cwd = str(self.workspace_path)

        current_llm_config = self.llm_manager.get_current_config_name() if self.llm_manager else None
        return TaskContext(
            user_id="cli_user",  # é»˜è®¤ç”¨æˆ·ID
            session_id=str(uuid.uuid4()),  # ç”Ÿæˆæ–°çš„ä¼šè¯ID
            message_id=str(uuid.uuid4()),  # ç”Ÿæˆæ–°çš„æ¶ˆæ¯ID
            workspace_path=str(self.workspace_path),
            metadata={
                "environment": os.environ.copy(),
                "variables": {
                    "workspace_path": str(self.workspace_path),
                    "workspace_uuid": self.uuid,
                    "llm_config": current_llm_config,
                },
            },
            task_files=[],
            task_images=[],
        )

    # ç”Ÿå‘½å‘¨æœŸç®¡ç†æ–¹æ³•
    async def cleanup(self) -> bool:
        """æ¸…ç†å·¥ä½œåŒºèµ„æºï¼ˆä½¿ç”¨ WorkspaceServiceï¼‰

        â­ æ”¹åŠ¨ï¼šé‡Šæ”¾å¯¹ WorkspaceContext çš„å¼•ç”¨ï¼Œè€Œä¸æ˜¯ç›´æŽ¥åœæ­¢å…±äº«èµ„æº

        Returns:
            bool: æ¸…ç†æ˜¯å¦æˆåŠŸ

        """
        if not self._initialized:
            return True

        logger.info(f"Cleaning up workspace: {self.uuid}")

        try:
            # åœæ­¢è‡ªåŠ¨ä¿å­˜ä»»åŠ¡
            await self._stop_auto_save_conversation()

            # ä¿å­˜å½“å‰å¯¹è¯
            if self.current_conversation and self.current_conversation.message_count > 0:
                await self.save_current_conversation()

            # ðŸ”§ ä¿®å¤å†…å­˜æ³„æ¼ï¼šæ¸…ç† TaskGraph çš„äº‹ä»¶å¤„ç†å™¨
            if self.task_graph:
                try:
                    self.task_graph.cleanup()
                    logger.info(f"  âœ“ Cleaned up TaskGraph event handlers")
                except Exception as e:
                    logger.warning(f"  âš ï¸ Failed to cleanup TaskGraph handlers: {e}")

            # â­ æ ¸å¿ƒæ”¹åŠ¨ï¼šé‡Šæ”¾å¯¹ WorkspaceContext çš„å¼•ç”¨ï¼ˆä¸åœæ­¢å…±äº«èµ„æºï¼‰
            if self._context:
                ref_count_before = self._context.ref_count
                await self._context.release()
                ref_count_after = self._context.ref_count  # åœ¨è®¾ä¸º None ä¹‹å‰èŽ·å–
                logger.info(f"  âœ“ Released WorkspaceContext (refs: {ref_count_before} â†’ {ref_count_after})")
                self._context = None

            self._initialized = False
            self._loaded = False
            logger.info(f"âœ“ Workspace cleanup completed successfully: {self.uuid}")
            return True

        except Exception as e:
            logger.error(f"Error cleaning up workspace: {e}", exc_info=True)
            return False

    async def reload(self) -> bool:
        """é‡æ–°åŠ è½½å·¥ä½œåŒº

        Returns:
            bool: é‡æ–°åŠ è½½æ˜¯å¦æˆåŠŸ

        """
        logger.info("Reloading workspace...")

        # å…ˆæ¸…ç†ï¼ˆä¼šè‡ªåŠ¨æ¸…ç† TaskGraph äº‹ä»¶å¤„ç†å™¨ï¼‰
        await self.cleanup()

        # é‡æ–°åˆå§‹åŒ–ï¼ˆä¼šåˆ›å»ºæ–°çš„ TaskGraph å¹¶æ³¨å†Œæ–°çš„äº‹ä»¶å¤„ç†å™¨ï¼‰
        success = await self.initialize()
        if success:
            logger.info("Workspace reloaded successfully")
        else:
            logger.error("Failed to reload workspace")

        return success

    def is_initialized(self) -> bool:
        """æ£€æŸ¥å·¥ä½œåŒºæ˜¯å¦å·²åˆå§‹åŒ–"""
        return self._initialized

    def is_loaded(self) -> bool:
        """æ£€æŸ¥å·¥ä½œåŒºæ˜¯å¦å·²åŠ è½½"""
        return self._loaded

    # åºåˆ—åŒ–æ–¹æ³•
    def to_dict(self) -> dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        # èŽ·å– LLM é…ç½®ä¿¡æ¯
        current_llm_config = self.llm_manager.get_current_config_name() if self.llm_manager else None
        llm_configs = {}
        if self.llm_manager:
            all_configs = self.llm_manager.get_all_configs()
            llm_configs = {name: config.config.__dict__ for name, config in all_configs.items()}

        return {
            "uuid": self.uuid,
            "absolute_path": self.absolute_path,
            "workspace_info": self.workspace_info.to_dict() if self.workspace_info else None,
            "current_llm_config": current_llm_config,
            "llm_configs": llm_configs,
            "mcp_configs": self.mcp_tool_manager.to_dict() if self.mcp_tool_manager else {},
            "workspace_settings": (self.workspace_settings.__dict__ if self.workspace_settings else None),
            "mode_llm_configs": self.llm_manager.get_mode_configs() if self.llm_manager else {},
            "current_conversation": (
                {
                    "id": self.current_conversation.id,
                    "title": self.current_conversation.title,
                    "message_count": self.current_conversation.message_count,
                }
                if self.current_conversation
                else None
            ),
            "available_tools_count": (len(self.tool_manager.load_tools()) if self.tool_manager else 0),
            "allowed_tools_count": (len(self._get_filtered_tool_names(self.tool_manager.load_tools())) if self.tool_manager else 0),
            "initialized": self._initialized,
            "loaded": self._loaded,
        }

    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        workspace_name = self.workspace_info.display_name if self.workspace_info else "Unknown"
        return f"UserWorkspace(name={workspace_name}, path={self.absolute_path})"

    def __repr__(self) -> str:
        """è¯¦ç»†å­—ç¬¦ä¸²è¡¨ç¤º"""
        return f"UserWorkspace(uuid={self.uuid}, name={self.workspace_info.display_name if self.workspace_info else 'Unknown'}, path={self.absolute_path}, initialized={self._initialized}, loaded={self._loaded})"

    def check_duplicate_tool_call(self) -> bool:
        """æ£€æŸ¥å½“å‰å¯¹è¯ä¸­æ˜¯å¦å­˜åœ¨é‡å¤çš„å·¥å…·è°ƒç”¨ï¼Œé¿å…æ— é™å¾ªçŽ¯

        æ£€æŸ¥ current_conversation ä¸­æœ€è¿‘3æ¬¡å·¥å…·è°ƒç”¨æ¶ˆæ¯ï¼Œå¦‚æžœæ˜¯åŒä¸€å·¥å…·å¹¶ä¸”å‚æ•°ä¹Ÿä¸€æ ·ï¼Œ
        è¯´æ˜Žæ˜¯æ— æ•ˆé‡å¤ã€‚æ­¤æ—¶åº”è¯¥ abort taskã€‚

        Returns:
            bool: å¦‚æžœæ£€æµ‹åˆ°é‡å¤å·¥å…·è°ƒç”¨è¿”å›ž Trueï¼Œå¦åˆ™è¿”å›ž False

        """
        # æ£€æŸ¥æ˜¯å¦æœ‰ current_conversation å’Œæ¶ˆæ¯
        if not self.current_conversation or not self.current_conversation.messages:
            return False

        # èŽ·å–æœ€è¿‘çš„æ¶ˆæ¯
        messages = self.current_conversation.messages

        # æ”¶é›†æœ€è¿‘çš„å·¥å…·è°ƒç”¨
        recent_tool_calls = []

        # ä»Žæœ€æ–°æ¶ˆæ¯å¼€å§‹å‘å‰æŸ¥æ‰¾å·¥å…·è°ƒç”¨
        for i in range(len(messages) - 1, -1, -1):
            message = messages[i]

            # å¦‚æžœæ˜¯ AI æ¶ˆæ¯å¹¶ä¸”æœ‰å·¥å…·è°ƒç”¨
            from dawei.entity.lm_messages import AssistantMessage, ToolCall

            if isinstance(message, AssistantMessage) and hasattr(message, "tool_calls") and message.tool_calls:
                for tool_call in message.tool_calls:
                    if isinstance(tool_call, ToolCall):
                        recent_tool_calls.append(
                            {
                                "name": tool_call.function.name,
                                "parameters": tool_call.function.arguments,
                                "tool_call_id": tool_call.tool_call_id,
                                "message_index": i,
                            },
                        )

            # å¦‚æžœå·²ç»æ‰¾åˆ°3ä¸ªå·¥å…·è°ƒç”¨ï¼Œåœæ­¢æœç´¢
            if len(recent_tool_calls) >= 3:
                break

        # å¦‚æžœå·¥å…·è°ƒç”¨å°‘äºŽ3ä¸ªï¼Œä¸è¿›è¡Œé‡å¤æ£€æŸ¥
        if len(recent_tool_calls) < 3:
            return False

        # æ£€æŸ¥æœ€è¿‘3ä¸ªå·¥å…·è°ƒç”¨æ˜¯å¦æ˜¯åŒä¸€å·¥å…·å¹¶ä¸”å‚æ•°ç›¸åŒ
        # æ³¨æ„ï¼šrecent_tool_calls æ˜¯æŒ‰æ—¶é—´å€’åºæŽ’åˆ—çš„ï¼Œæ‰€ä»¥æœ€è¿‘çš„æ˜¯ç¬¬ä¸€ä¸ª
        latest_call = recent_tool_calls[0]
        second_call = recent_tool_calls[1]
        third_call = recent_tool_calls[2]

        # æ£€æŸ¥å·¥å…·åç§°æ˜¯å¦ç›¸åŒ
        if latest_call["name"] == second_call["name"] == third_call["name"]:
            # æ£€æŸ¥å‚æ•°æ˜¯å¦ç›¸åŒ
            if latest_call["parameters"] == second_call["parameters"] == third_call["parameters"]:
                return True

        return False

    async def _on_persist_task_graph(self, event: Any) -> None:
        """å¤„ç†ä»»åŠ¡å›¾æŒä¹…åŒ–äº‹ä»¶

        å½“ TaskGraph å‘ç”Ÿå˜åŒ–æ—¶ï¼Œæ­¤æ–¹æ³•è¢«è°ƒç”¨ä»¥è§¦å‘ä¿å­˜

        Args:
            event: æŒä¹…åŒ–äº‹ä»¶ï¼ŒåŒ…å« task_graph_id

        """
        try:
            # æå–äº‹ä»¶æ•°æ®
            if hasattr(event, "data") and hasattr(event.data, "get_event_data"):
                data = event.data.get_event_data()
            elif hasattr(event, "data"):
                data = event.data if isinstance(event.data, dict) else {}
            else:
                data = {}

            task_graph_id = data.get("task_graph_id")

            if not task_graph_id:
                logger.warning("Persist task graph event missing task_graph_id")
                return

            # éªŒè¯ TaskGraph å­˜åœ¨
            if not self.task_graph or self.task_graph.task_node_id != task_graph_id:
                logger.warning(f"TaskGraph {task_graph_id} not found in workspace")
                return

            # è°ƒç”¨çŽ°æœ‰çš„ save_task_graph æ–¹æ³•
            success = await self.save_task_graph(self.task_graph)

            if success:
                logger.info(f"Task graph {task_graph_id} persisted successfully")
            else:
                logger.warning(f"Task graph {task_graph_id} persistence returned False")

        except Exception as e:
            logger.error(f"Error persisting task graph: {e}", exc_info=True)
            # ä¸é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…ä¸­æ–­äº‹ä»¶å¤„ç†

    async def save_task_graph(self, task_graph) -> bool:
        """ä¿å­˜ä»»åŠ¡å›¾åˆ°æ–‡ä»¶ (ä½¿ç”¨æŒä¹…åŒ–ç®¡ç†å™¨)

        Args:
            task_graph: ä»»åŠ¡å›¾å®žä¾‹

        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ

        """
        try:
            # å‡†å¤‡ä»»åŠ¡å›¾æ•°æ®
            all_tasks = await task_graph.get_all_tasks()

            # all_tasks æ˜¯ List[TaskNode],éœ€è¦è½¬æ¢ä¸ºå­—å…¸
            nodes_dict = {}
            for task in all_tasks:
                # ðŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ task_node_id è€Œä¸æ˜¯ task_idï¼Œä¸” to_dict() ä¸æ˜¯å¼‚æ­¥æ–¹æ³•
                task_id = task.task_node_id
                nodes_dict[task_id] = task.to_dict()

            task_data = {
                "task_graph_id": task_graph.task_node_id,
                "timestamp": datetime.now(UTC).isoformat(),
                "nodes": nodes_dict,
                "total_tasks": len(all_tasks),
            }

            # é¦–å…ˆå°è¯•ä½¿ç”¨æŒä¹…åŒ–ç®¡ç†å™¨ä¿å­˜
            if self.persistence_manager:
                success = await self.persistence_manager.save_task_graph(
                    task_graph.task_node_id,
                    task_data,
                )

                if success:
                    logger.info(
                        f"Task graph saved via persistence manager: {task_graph.task_node_id}",
                    )

                    # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä¿å­˜æ—§æ ¼å¼

                    return True
                logger.warning(
                    "Persistence manager save failed for task graph",
                )

        except Exception as e:
            logger.error(f"Failed to save task graph: {e}", exc_info=True)
            # å‘é€æŒä¹…åŒ–å¤±è´¥å‘Šè­¦
            await self._alert_persistence_failure(
                "task_graph",
                f"Failed to save task graph: {e!s}",
                task_graph_id=task_graph.task_node_id,
            )
            raise TaskGraphPersistenceError(
                f"Failed to save task graph: {e}",
                task_graph_id=task_graph.task_node_id,
            )

    async def load_task_graph(self) -> Any | None:
        """ä»Žæ–‡ä»¶æ¢å¤ä»»åŠ¡å›¾

        Returns:
            ä»»åŠ¡å›¾å®žä¾‹æˆ–None

        """
        try:
            if not self.tasks_file.exists():
                logger.info("No task graph file found, creating empty task graph")
                return None

            with Path(self.tasks_file).open(encoding="utf-8") as f:
                task_data = json.load(f)

            logger.info(f"Task graph loaded from {self.tasks_file}")

            # è¿™é‡Œè¿”å›žä»»åŠ¡å›¾æ•°æ®ï¼Œè€Œä¸æ˜¯TaskGraphå®žä¾‹
            # å› ä¸ºTaskGraphçš„åˆ›å»ºéœ€è¦event_buså‚æ•°
            return task_data

        except Exception:
            logger.exception("Failed to load task graph: ")
            return None

    async def create_or_restore_task_graph(self):
        """åˆ›å»ºæˆ–æ¢å¤ä»»åŠ¡å›¾
        Returns:
            TaskGraph: ä»»åŠ¡å›¾å®žä¾‹
        """
        from dawei.task_graph.task_graph import TaskGraph

        # å°è¯•æ¢å¤ä»»åŠ¡å›¾
        task_graph_data = await self.load_task_graph()

        if task_graph_data:
            # åˆ›å»ºæ–°çš„TaskGraphå®žä¾‹
            task_graph = TaskGraph(
                task_id=task_graph_data["task_graph_id"],
                event_bus=None,  # ä¸å†ä½¿ç”¨ workspace çš„ event_bus
            )

            # æ¢å¤èŠ‚ç‚¹æ•°æ®
            from dawei.task_graph.task_node import TaskNode
            from dawei.task_graph.task_node_data import TaskData

            # å…ˆåˆ›å»ºæ‰€æœ‰èŠ‚ç‚¹
            nodes = {}
            for task_id, node_data in task_graph_data["nodes"].items():
                # åˆ›å»ºTaskData
                task_data_obj = TaskData.from_dict(node_data["data"])

                # åˆ›å»ºTaskNode
                task_node = TaskNode.create_child(task_node_id=task_id, description=task_data_obj.description, mode=task_data_obj.mode, parent_id=node_data["parent_id"]) if node_data.get("parent_id") else TaskNode.create_root(task_node_id=task_id, description=task_data_obj.description, mode=task_data_obj.mode)

                nodes[task_id] = task_node

            # åˆ›å»ºæ ¹èŠ‚ç‚¹
            root_task_id = None
            for task_id, node_data in task_graph_data["nodes"].items():
                if not node_data.get("parent_id"):
                    root_task_id = task_id
                    break

            if root_task_id and root_task_id in nodes:
                root_task = nodes[root_task_id]
                await task_graph.create_root_task(root_task.data)

                # æ›´æ–°å­èŠ‚ç‚¹å…³ç³»
                for task_id, node_data in task_graph_data["nodes"].items():
                    if node_data.get("parent_id"):
                        for child_id in node_data["child_ids"]:
                            if child_id in task_graph_data["nodes"]:
                                await task_graph.create_subtask(
                                    task_id,
                                    TaskData.from_dict(task_graph_data["nodes"][child_id]["data"]),
                                )

            logger.info(f"Task graph restored with {len(task_graph_data['nodes'])} nodes")
            return task_graph

        # åˆ›å»ºç©ºçš„ä»»åŠ¡å›¾
        logger.info("Creating empty task graph")
        # ðŸ”´ ä¿®å¤ï¼šTaskGraph ä¸å†ä½¿ç”¨ UserWorkspace çš„ event_bus
        return TaskGraph(task_id="default", event_bus=None)

    # ==================== æŒä¹…åŒ–å¤±è´¥å‘Šè­¦æœºåˆ¶ ====================

    async def _alert_persistence_failure(self, resource_type: str, error_message: str, **kwargs):
        """å‘é€æŒä¹…åŒ–å¤±è´¥å‘Šè­¦

        Args:
            resource_type: èµ„æºç±»åž‹ (workspace_info, conversation, task_graph, checkpoint)
            error_message: é”™è¯¯ä¿¡æ¯
            **kwargs: é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ (conversation_id, task_graph_id, checkpoint_idç­‰)

        """
        try:
            # æž„å»ºå‘Šè­¦æ•°æ®
            alert_data = {
                "alert_type": "persistence_failure",
                "resource_type": resource_type,
                "error_message": error_message,
                "timestamp": datetime.now(UTC).isoformat(),
                "workspace_path": self.absolute_path,
                "workspace_id": self.workspace_info.id if self.workspace_info else self.uuid,
                **kwargs,
            }

            # 1. è®°å½•åˆ°é”™è¯¯æ—¥å¿—
            logger.error(
                f"[PERSISTENCE_FAILURE] {resource_type}: {error_message}",
                extra={"alert_data": alert_data},
            )

            # ðŸ”´ ä¿®å¤ï¼šUserWorkspace ä¸å†ä½¿ç”¨ event_bus,æ‰€ä»¥ä¸å‘é€äº‹ä»¶
            # å¦‚æžœéœ€è¦å‘é€äº‹ä»¶ï¼Œåº”è¯¥ä½¿ç”¨ Agent çš„ event_bus
            # if self.event_bus:
            #     try:
            #         await self.event_bus.emit("persistence_failure", alert_data)
            #     except Exception as e:
            #         logger.warning(f"Failed to emit persistence_failure event: {e}")

            # 3. ä¿å­˜åˆ°æŒä¹…åŒ–å¤±è´¥æ—¥å¿—æ–‡ä»¶
            await self._log_persistence_failure(alert_data)

            # 4. å¦‚æžœæœ‰WebSocketè¿žæŽ¥,å‘é€å®žæ—¶é€šçŸ¥ (å¯é€‰)
            # è¿™éœ€è¦è®¿é—®WebSocketæœåŠ¡å™¨,æš‚æ—¶è·³è¿‡

        except Exception as e:
            logger.error(f"Failed to send persistence failure alert: {e}", exc_info=True)

    async def _log_persistence_failure(self, alert_data: dict[str, Any]):
        """å°†æŒä¹…åŒ–å¤±è´¥è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶

        Args:
            alert_data: å‘Šè­¦æ•°æ®

        """
        try:
            # åˆ›å»ºæŒä¹…åŒ–å¤±è´¥æ—¥å¿—ç›®å½•
            failure_log_dir = self.workspace_path / ".dawei" / "persistence_failures"
            failure_log_dir.mkdir(parents=True, exist_ok=True)

            # ç”Ÿæˆæ—¥å¿—æ–‡ä»¶å
            timestamp = datetime.now(UTC).strftime("%Y%m%d")
            log_file = failure_log_dir / f"failures_{timestamp}.jsonl"

            # è¿½åŠ å†™å…¥æ—¥å¿— (JSONLæ ¼å¼)
            with Path(log_file, "a").open(encoding="utf-8") as f:
                f.write(json.dumps(alert_data, ensure_ascii=False) + "\n")

            logger.debug(f"Persistence failure logged to {log_file}")

        except Exception as e:
            logger.warning(f"Failed to log persistence failure to file: {e}")

    async def get_persistence_failures(self, limit: int = 100) -> list[dict[str, Any]]:
        """èŽ·å–æŒä¹…åŒ–å¤±è´¥è®°å½•

        Args:
            limit: æœ€å¤šè¿”å›žçš„å¤±è´¥è®°å½•æ•°

        Returns:
            å¤±è´¥è®°å½•åˆ—è¡¨,æŒ‰æ—¶é—´å€’åº

        Raises:
            PersistenceError: å½“è¯»å–æŒä¹…åŒ–å¤±è´¥æ–‡ä»¶å¤±è´¥æ—¶
            FileNotFoundError: å½“å¤±è´¥æ—¥å¿—ç›®å½•ä¸å­˜åœ¨æ—¶

        """
        failure_log_dir = self.workspace_path / ".dawei" / "persistence_failures"

        if not failure_log_dir.exists():
            return []

        # è¯»å–æ‰€æœ‰å¤±è´¥æ—¥å¿—æ–‡ä»¶
        failures = []
        for log_file in sorted(failure_log_dir.glob("failures_*.jsonl"), reverse=True):
            with Path(log_file).open(encoding="utf-8") as f:
                for line in f:
                    if line.strip():
                        try:
                            failure = json.loads(line)
                            failures.append(failure)
                            if len(failures) >= limit:
                                break
                        except json.JSONDecodeError:
                            continue

            if len(failures) >= limit:
                break

        return failures

    def clear_persistence_failures(self) -> bool:
        """æ¸…é™¤æŒä¹…åŒ–å¤±è´¥æ—¥å¿—

        Returns:
            æ˜¯å¦æ¸…é™¤æˆåŠŸ

        Raises:
            PersistenceError: å½“æ¸…é™¤æŒä¹…åŒ–å¤±è´¥æ—¥å¿—å¤±è´¥æ—¶
            OSError: å½“æ–‡ä»¶ç³»ç»Ÿæ“ä½œå¤±è´¥æ—¶

        """
        failure_log_dir = self.workspace_path / ".dawei" / "persistence_failures"

        if failure_log_dir.exists():
            import shutil

            shutil.rmtree(failure_log_dir)
            logger.info("Cleared persistence failure logs")

        return True

    # ==================== å¯¹è¯è‡ªåŠ¨ä¿å­˜æœºåˆ¶ ====================

    async def _start_auto_save_conversation(self):
        """å¯åŠ¨å¯¹è¯è‡ªåŠ¨ä¿å­˜ä»»åŠ¡"""
        if not self._auto_save_enabled:
            logger.info("Auto-save is disabled")
            return

        if self._auto_save_task is not None:
            logger.warning("Auto-save task is already running")
            return

        logger.info(f"Starting auto-save task (interval: {self._auto_save_interval}s)")
        self._auto_save_task = asyncio.create_task(self._auto_save_conversation_loop())
        logger.info("Auto-save task started")

    async def _stop_auto_save_conversation(self):
        """åœæ­¢å¯¹è¯è‡ªåŠ¨ä¿å­˜ä»»åŠ¡"""
        if self._auto_save_task is None:
            return

        logger.info("Stopping auto-save task...")

        # å–æ¶ˆä»»åŠ¡
        self._auto_save_task.cancel()

        try:
            await self._auto_save_task
        except asyncio.CancelledError:
            logger.info("Auto-save task cancelled")

        self._auto_save_task = None
        logger.info("Auto-save task stopped")

    async def _auto_save_conversation_loop(self):
        """è‡ªåŠ¨ä¿å­˜å¯¹è¯å¾ªçŽ¯"""
        while self._initialized:
            await asyncio.sleep(self._auto_save_interval)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜
            if self.current_conversation and self._should_auto_save_conversation():
                logger.debug("Auto-saving conversation...")
                success = await self.save_current_conversation()

                if success:
                    self._last_message_count = self.current_conversation.message_count
                    logger.debug(
                        f"Conversation auto-saved ({self.current_conversation.message_count} messages)",
                    )
                else:
                    logger.warning("Conversation auto-save failed")

        logger.info("Auto-save loop completed")

    def _should_auto_save_conversation(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è‡ªåŠ¨ä¿å­˜å¯¹è¯"""
        if not self.current_conversation:
            return False

        # æ£€æŸ¥æ¶ˆæ¯æ•°é‡æ˜¯å¦å¢žåŠ 
        current_count = self.current_conversation.message_count
        if current_count > self._last_message_count:
            return True

        # æ£€æŸ¥æ˜¯å¦æœ‰æœªä¿å­˜çš„æ›´æ”¹
        # (å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šæ£€æŸ¥æ¡ä»¶)

        return False

    async def set_auto_save_interval(self, interval_seconds: int):
        """è®¾ç½®è‡ªåŠ¨ä¿å­˜é—´éš”

        Args:
            interval_seconds: ä¿å­˜é—´éš”(ç§’)

        """
        if interval_seconds < 5:
            logger.warning("Auto-save interval too short, using minimum 5 seconds")
            interval_seconds = 5

        old_interval = self._auto_save_interval
        self._auto_save_interval = interval_seconds
        logger.info(f"Auto-save interval changed: {old_interval}s -> {interval_seconds}s")

        # é‡å¯è‡ªåŠ¨ä¿å­˜ä»»åŠ¡
        if self._auto_save_task is not None:
            await self._stop_auto_save_conversation()
            await self._start_auto_save_conversation()

    def enable_auto_save(self):
        """å¯ç”¨è‡ªåŠ¨ä¿å­˜"""
        if not self._auto_save_enabled:
            self._auto_save_enabled = True
            logger.info("Auto-save enabled")

    def disable_auto_save(self):
        """ç¦ç”¨è‡ªåŠ¨ä¿å­˜"""
        if self._auto_save_enabled:
            self._auto_save_enabled = False
            logger.info("Auto-save disabled")

    # ==================== æŒä¹…åŒ–é‡è¯•æœºåˆ¶ ====================

    async def _save_with_retry(self, save_func, resource_type: str, *args, **kwargs) -> bool:
        """å¸¦é‡è¯•çš„æŒä¹…åŒ–ä¿å­˜

        Args:
            save_func: ä¿å­˜å‡½æ•°
            resource_type: èµ„æºç±»åž‹(ç”¨äºŽæ—¥å¿—)
            *args: ä¼ é€’ç»™ä¿å­˜å‡½æ•°çš„ä½ç½®å‚æ•°
            **kwargs: ä¼ é€’ç»™ä¿å­˜å‡½æ•°çš„å…³é”®å­—å‚æ•°

        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ

        """
        last_exception = None

        for attempt in range(self._max_retry_attempts):
            try:
                # å°è¯•ä¿å­˜
                result = await save_func(*args, **kwargs)

                if result:
                    if attempt > 0:
                        logger.info(f"{resource_type} saved successfully after {attempt} retries")
                    return True
                # ä¿å­˜å¤±è´¥ä½†æ²¡æŠ›å‡ºå¼‚å¸¸
                last_exception = Exception("Save function returned False")
                logger.warning(
                    f"{resource_type} save attempt {attempt + 1}/{self._max_retry_attempts} failed",
                )

            except Exception as e:
                last_exception = e
                logger.warning(
                    f"{resource_type} save attempt {attempt + 1}/{self._max_retry_attempts} failed: {e}",
                )

            # å¦‚æžœä¸æ˜¯æœ€åŽä¸€æ¬¡å°è¯•,ç­‰å¾…åŽé‡è¯•
            if attempt < self._max_retry_attempts - 1:
                delay = self._calculate_retry_delay(attempt)
                logger.info(f"Retrying {resource_type} save in {delay:.1f} seconds...")
                await asyncio.sleep(delay)

        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        logger.error(
            f"{resource_type} save failed after {self._max_retry_attempts} attempts: {last_exception}",
        )

        # å‘é€æŒä¹…åŒ–å¤±è´¥å‘Šè­¦
        await self._alert_persistence_failure(
            resource_type,
            f"Failed after {self._max_retry_attempts} retries: {last_exception!s}",
        )

        return False

    def _calculate_retry_delay(self, attempt: int) -> float:
        """è®¡ç®—é‡è¯•å»¶è¿Ÿ(æŒ‡æ•°é€€é¿)

        Args:
            attempt: å½“å‰å°è¯•æ¬¡æ•°(ä»Ž0å¼€å§‹)

        Returns:
            float: å»¶è¿Ÿç§’æ•°

        """
        # æŒ‡æ•°é€€é¿: delay = base_delay * (multiplier ^ attempt)
        delay = self._retry_base_delay * (self._retry_backoff_multiplier**attempt)

        # é™åˆ¶æœ€å¤§å»¶è¿Ÿ
        return min(delay, self._retry_max_delay)

    async def save_workspace_info_with_retry(self) -> bool:
        """å¸¦é‡è¯•çš„ Workspace ä¿¡æ¯ä¿å­˜

        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ

        """
        return await self._save_with_retry(self._save_workspace_info, "workspace_info")

    async def save_conversation_with_retry(self) -> bool:
        """å¸¦é‡è¯•çš„å¯¹è¯ä¿å­˜

        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ

        """
        return await self._save_with_retry(self.save_current_conversation, "conversation")

    async def save_task_graph_with_retry(self, task_graph) -> bool:
        """å¸¦é‡è¯•çš„ä»»åŠ¡å›¾ä¿å­˜

        Args:
            task_graph: ä»»åŠ¡å›¾å®žä¾‹

        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ

        """
        return await self._save_with_retry(self.save_task_graph, "task_graph", task_graph)

    # ==================== UI ä¸Šä¸‹æ–‡è‡ªåŠ¨ä¿å­˜ ====================

    async def update_ui_context_auto(
        self,
        open_files: list[str] | None = None,
        current_file: str | None = None,
        current_selected_content: str | None = None,
        current_mode: str | None = None,
        conversation_id: str | None = None,
    ) -> bool:
        """è‡ªåŠ¨æ›´æ–°å¹¶ä¿å­˜ UI ä¸Šä¸‹æ–‡

        Args:
            open_files: æ‰“å¼€çš„æ–‡ä»¶åˆ—è¡¨
            current_file: å½“å‰æ–‡ä»¶
            current_selected_content: å½“å‰é€‰ä¸­å†…å®¹
            current_mode: å½“å‰æ¨¡å¼
            conversation_id: å½“å‰å¯¹è¯ID

        Returns:
            bool: æ˜¯å¦æ›´æ–°ä¿å­˜æˆåŠŸ

        """
        if not self.workspace_info or not self.workspace_info.user_ui_context:
            logger.warning("Cannot update UI context: workspace_info or user_ui_context is None")
            return False

        # æ›´æ–° UI ä¸Šä¸‹æ–‡

        context = self.workspace_info.user_ui_context

        if open_files is not None:
            context.open_files = open_files
            self._ui_context_dirty = True

        if current_file is not None:
            context.current_file = current_file
            self._ui_context_dirty = True

        if current_selected_content is not None:
            context.current_selected_content = current_selected_content
            self._ui_context_dirty = True

        if current_mode is not None:
            context.current_mode = current_mode
            self._ui_context_dirty = True

        if conversation_id is not None:
            context.conversation_id = conversation_id
            self._ui_context_dirty = True

        # å¦‚æžœæœ‰æ›´æ–°,è‡ªåŠ¨ä¿å­˜
        if self._ui_context_dirty:
            return await self.save_workspace_info_with_retry()

        return True

    async def on_file_opened(self, file_path: str):
        """æ–‡ä»¶æ‰“å¼€æ—¶è‡ªåŠ¨ä¿å­˜ UI ä¸Šä¸‹æ–‡

        Args:
            file_path: æ‰“å¼€çš„æ–‡ä»¶è·¯å¾„

        """
        if not self.workspace_info or not self.workspace_info.user_ui_context:
            return

        context = self.workspace_info.user_ui_context

        # æ·»åŠ åˆ°æ‰“å¼€æ–‡ä»¶åˆ—è¡¨(å¦‚æžœä¸å­˜åœ¨)
        if file_path not in context.open_files:
            context.open_files.append(file_path)

        # è®¾ç½®ä¸ºå½“å‰æ–‡ä»¶
        context.current_file = file_path

        # è‡ªåŠ¨ä¿å­˜
        await self.update_ui_context_auto(open_files=context.open_files, current_file=file_path)

    async def on_file_closed(self, file_path: str):
        """æ–‡ä»¶å…³é—­æ—¶è‡ªåŠ¨ä¿å­˜ UI ä¸Šä¸‹æ–‡

        Args:
            file_path: å…³é—­çš„æ–‡ä»¶è·¯å¾„

        """
        if not self.workspace_info or not self.workspace_info.user_ui_context:
            return

        context = self.workspace_info.user_ui_context

        # ä»Žæ‰“å¼€æ–‡ä»¶åˆ—è¡¨ç§»é™¤
        if file_path in context.open_files:
            context.open_files.remove(file_path)

        # å¦‚æžœå…³é—­çš„æ˜¯å½“å‰æ–‡ä»¶,æ¸…é™¤å½“å‰æ–‡ä»¶
        if context.current_file == file_path:
            context.current_file = context.open_files[-1] if context.open_files else None

        # è‡ªåŠ¨ä¿å­˜
        await self.update_ui_context_auto(
            open_files=context.open_files,
            current_file=context.current_file,
        )

    async def on_conversation_changed(self, conversation_id: str):
        """å¯¹è¯åˆ‡æ¢æ—¶è‡ªåŠ¨ä¿å­˜ UI ä¸Šä¸‹æ–‡

        Args:
            conversation_id: æ–°çš„å¯¹è¯ID

        """
        await self.update_ui_context_auto(conversation_id=conversation_id)

    async def on_mode_changed(self, mode: str):
        """æ¨¡å¼åˆ‡æ¢æ—¶è‡ªåŠ¨ä¿å­˜ UI ä¸Šä¸‹æ–‡

        Args:
            mode: æ–°çš„æ¨¡å¼

        """
        await self.update_ui_context_auto(current_mode=mode)


# ä¾¿æ·å‡½æ•°
async def create_workspace(workspace_path: str) -> UserWorkspace:
    """åˆ›å»ºå¹¶åˆå§‹åŒ–å·¥ä½œåŒºçš„ä¾¿æ·å‡½æ•°

    Args:
        workspace_path: å·¥ä½œåŒºè·¯å¾„

    Returns:
        UserWorkspace: åˆå§‹åŒ–åŽçš„å·¥ä½œåŒºå®žä¾‹

    """
    workspace = UserWorkspace(workspace_path)
    await workspace.initialize()
    return workspace


def load_workspace(workspace_path: str) -> UserWorkspace:
    """åŠ è½½å·¥ä½œåŒºçš„ä¾¿æ·å‡½æ•°ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œä»…åˆ›å»ºå®žä¾‹ï¼‰

    Args:
        workspace_path: å·¥ä½œåŒºè·¯å¾„

    Returns:
        UserWorkspace: å·¥ä½œåŒºå®žä¾‹

    """
    return UserWorkspace(workspace_path)
