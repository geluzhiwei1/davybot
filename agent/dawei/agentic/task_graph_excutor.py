# Copyright (c) 2025 æ ¼å¾‹è‡³å¾®
# SPDX-License-Identifier: AGPL-3.0-only

"""ä»»åŠ¡æ‰§è¡Œå¼•æ“
è´Ÿè´£ä»»åŠ¡çš„æ‰§è¡Œã€æ¶ˆæ¯å¤„ç†å’Œå·¥å…·è°ƒç”¨

é‡æ„ç‰ˆæœ¬ï¼šä½¿ç”¨æ¥å£æŠ½è±¡è€Œéç›´æ¥ä¾èµ–å…·ä½“å®ç°
"""

import asyncio
import uuid
from typing import Any

# å¯¼å…¥é”™è¯¯ç±»å‹
from dawei.agentic.errors import TaskExecutionError, ToolExecutionError
from dawei.core.errors import (
    CheckpointError,
    ConfigurationError,
    StorageError,
    TaskNotFoundError,
    TaskStateError,
    ValidationError,
)
from dawei.entity.task_types import TaskStatus
from dawei.entity.user_input_message import UserInputMessage

# å¯¼å…¥æ–°çš„æ¥å£
from dawei.interfaces import ILLMService, IMessageProcessor, IToolCallService
from dawei.logg.logging import get_logger
from dawei.task_graph.task_node import TaskNode
from dawei.workspace.user_workspace import UserWorkspace

from .task_node_executor import TaskNodeExecutionEngine


class TaskGraphExecutionEngine:
    """ä»»åŠ¡æ‰§è¡Œå¼•æ“å®ç°
    å§”æ‰˜ç»™ TaskNodeExecutionEngine æ‰§è¡Œä»»åŠ¡
    """

    def __init__(
        self,
        user_workspace: UserWorkspace,
        message_processor: IMessageProcessor,
        llm_service: ILLMService,
        tool_call_service: IToolCallService,
        config: Any,
        agent=None,  # æ·»åŠ agentå¼•ç”¨ç”¨äºæš‚åœæ£€æŸ¥
    ):
        """åˆå§‹åŒ–ä»»åŠ¡å›¾æ‰§è¡Œå¼•æ“

        Args:
            user_workspace: ç”¨æˆ·å·¥ä½œåŒºå®ä¾‹
            message_processor: æ¶ˆæ¯å¤„ç†å™¨æ¥å£å®ä¾‹
            llm_service: LLM æœåŠ¡æ¥å£å®ä¾‹
            tool_call_service: å·¥å…·è°ƒç”¨æœåŠ¡æ¥å£å®ä¾‹
            event_bus: äº‹ä»¶æ€»çº¿æ¥å£å®ä¾‹
            config: ç»Ÿä¸€é…ç½®å®ä¾‹
            agent: Agentå®ä¾‹ï¼ˆå¯é€‰ï¼Œç”¨äºæš‚åœ/æ¢å¤æ§åˆ¶ï¼‰

        """
        if user_workspace is None:
            raise ConfigurationError("user_workspace must be provided")

        # åˆå§‹åŒ–loggerï¼ˆå¿…é¡»åœ¨æœ€å¼€å§‹ï¼‰
        self.logger = get_logger(__name__)

        self._user_workspace = user_workspace
        self._message_processor = message_processor
        self._llm_service = llm_service
        self._tool_call_service = tool_call_service
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ Agent çš„ event_bus
        # è¿™æ ·ç¡®ä¿ ExecutionEngineã€TaskNodeExecutor å’Œ Agent ä½¿ç”¨åŒä¸€ä¸ª event_bus
        # WebSocket handler è®¢é˜…çš„æ˜¯ Agent çš„ event_busï¼Œæ‰€ä»¥æ‰€æœ‰äº‹ä»¶éƒ½å¿…é¡»å‘é€åˆ°é‚£é‡Œ
        if not agent:
            raise ConfigurationError("agent must be provided for event_bus")
        if not hasattr(agent, 'event_bus'):
            raise ConfigurationError("agent must have event_bus attribute")
        self._event_bus = agent.event_bus
        self._config = config
        self._agent = agent  # ä¿å­˜agentå¼•ç”¨

        # éªŒè¯å¿…è¦çš„æœåŠ¡æ˜¯å¦å¯ç”¨
        if message_processor is None:
            raise ConfigurationError("message_processor must be provided")
        if llm_service is None:
            raise ConfigurationError("llm_service must be provided")
        if tool_call_service is None:
            raise ConfigurationError("tool_call_service must be provided")

        # ä»»åŠ¡èŠ‚ç‚¹æ‰§è¡Œå¼•æ“ç®¡ç†
        self._node_executors: dict[str, TaskNodeExecutionEngine] = {}

        # æ‰§è¡ŒçŠ¶æ€è·Ÿè¸ª
        self._execution_status: dict[str, TaskStatus] = {}
        self._execution_tasks: dict[str, asyncio.Task] = {}

        # é”
        self._lock = asyncio.Lock()

        # å½“å‰æ‰§è¡Œçš„ä»»åŠ¡èŠ‚ç‚¹IDï¼ˆç”¨äºè·å–å½“å‰æ­¥éª¤æè¿°ï¼‰
        self._current_task_node_id: str | None = None

        # æœ€å¤§å¹¶è¡Œä»»åŠ¡èŠ‚ç‚¹æ•°é™åˆ¶ï¼ˆä»é…ç½®è¯»å–ï¼Œé»˜è®¤ä¸º2ï¼‰
        self._max_parallel_tasks = getattr(config, "max_parallel_tasks", 2)
        self._parallel_semaphore = asyncio.Semaphore(self._max_parallel_tasks)
        self.logger.info(
            f"TaskGraphExecutionEngine initialized with max_parallel_tasks={self._max_parallel_tasks}",
        )

    async def execute_task_graph(self) -> TaskStatus:
        """æ‰§è¡Œä»»åŠ¡å›¾
        æ ¹æ®ä»»åŠ¡å›¾ä¸­çš„èŠ‚ç‚¹é¡ºåºå’Œä¾èµ–å…³ç³»æ‰§è¡Œä»»åŠ¡
        å¤šä¸ªæ²¡æœ‰ä¾èµ–å…³ç³»çš„nodeå¯å¹¶è¡Œæ‰§è¡Œ

        Returns:
            æœ€ç»ˆæ‰§è¡ŒçŠ¶æ€

        """
        try:
            # è·å–æ ¹ä»»åŠ¡
            root_task = await self._user_workspace.task_graph.get_root_task()
            if not root_task:
                self.logger.error("No root task found in task graph")
                raise TaskNotFoundError("No root task found in task graph")

            # åˆå§‹åŒ–æ‰§è¡ŒçŠ¶æ€
            await self._initialize_execution_status()

            # æ‰§è¡Œä»»åŠ¡å›¾
            final_status = await self._execute_task_graph_recursive(root_task)
            self.logger.info(f"Task graph execution completed with status: {final_status.value}")

            # è§¦å‘ä»»åŠ¡å®Œæˆäº‹ä»¶
            await self._emit_task_completion_event(root_task.task_node_id, final_status)

            return final_status

        except TaskNotFoundError:
            self.logger.exception("Task execution failed: ")
            await self._emit_task_completion_event("unknown", TaskStatus.FAILED)
            raise
        except ConfigurationError:
            self.logger.exception("Configuration error in task execution: ")
            await self._emit_task_completion_event("unknown", TaskStatus.FAILED)
            raise
        except Exception as e:
            self.logger.error(f"Unexpected error during task graph execution: {e}", exc_info=True)
            await self._emit_task_completion_event("unknown", TaskStatus.FAILED)
            raise TaskExecutionError("unknown", f"Task graph execution failed: {e}")

    async def _emit_task_completion_event(self, task_id: str, status: TaskStatus) -> None:
        """å‘é€ä»»åŠ¡å®Œæˆäº‹ä»¶

        Args:
            task_id: ä»»åŠ¡ID
            status: ä»»åŠ¡çŠ¶æ€

        """
        from dawei.core.events import TaskEventType, emit_typed_event

        task_completed_data = {
            "result": f"Task completed with status: {status.value}",
            "task_id": task_id,
            "status": status.value,
        }

        await emit_typed_event(
            TaskEventType.TASK_COMPLETED,
            task_completed_data,
            self._event_bus,
            task_id=task_id,
            source="task_graph_excutor",
        )
        self.logger.info(f"Emitted TASK_COMPLETED event for task {task_id}")

    async def _initialize_execution_status(self) -> None:
        """åˆå§‹åŒ–æ‰§è¡ŒçŠ¶æ€"""
        try:
            async with self._lock:  # æ·»åŠ é”ä¿æŠ¤
                all_tasks = await self._user_workspace.task_graph.get_all_tasks()
                if all_tasks is None:
                    raise TaskNotFoundError("No tasks found in task graph")

                for task in all_tasks:
                    if task.task_node_id is None:
                        raise ValidationError("Task with None ID found in task graph")
                    self._execution_status[task.task_node_id] = task.status
        except Exception as e:
            self.logger.error(f"Failed to initialize execution status: {e}", exc_info=True)
            raise TaskExecutionError(
                "unknown",
                f"Failed to initialize execution status: {e}",
            )

    async def _execute_task_graph_recursive(self, current_task: TaskNode) -> TaskStatus:
        """é€’å½’æ‰§è¡Œä»»åŠ¡å›¾
        ç¡®ä¿çˆ¶ä»»åŠ¡å®Œæˆåæ‰æ‰§è¡Œå­ä»»åŠ¡
        ä¿®æ”¹åæ”¯æŒå¤šè½®æ‰§è¡Œæœºåˆ¶ï¼šç­‰å¾…æ‰€æœ‰nodeå®Œæˆåæ‰ç»“æŸ

        Args:
            current_task: å½“å‰ä»»åŠ¡èŠ‚ç‚¹

        Returns:
            æ‰§è¡ŒçŠ¶æ€

        """
        task_node_id = current_task.task_node_id

        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²å®Œæˆ
        if await self._is_task_already_completed(task_node_id):
            return self._execution_status[task_node_id]

        # åˆ›å»ºæˆ–è·å–ä»»åŠ¡æ‰§è¡Œå¼•æ“
        executor = self._get_or_create_executor(current_task, task_node_id)

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
        await self._update_task_status(task_node_id, TaskStatus.RUNNING)

        try:
            # æ‰§è¡Œä»»åŠ¡å¹¶å¤„ç†ç»“æœ
            return await self._execute_task_and_handle_completion(
                current_task,
                task_node_id,
                executor,
            )

        except asyncio.CancelledError:
            return await self._handle_task_cancellation(task_node_id)
        except (TaskExecutionError, ToolExecutionError, ValueError, KeyError) as e:
            return await self._handle_task_error(task_node_id, e, "business error")
        except (OSError, RuntimeError, ConnectionError) as e:
            # Unexpected but recoverable errors
            return await self._handle_task_error(task_node_id, e, "unexpected error")

    async def _is_task_already_completed(self, task_node_id: str) -> bool:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²å®Œæˆ

        Args:
            task_node_id: ä»»åŠ¡èŠ‚ç‚¹ID

        Returns:
            å¦‚æœä»»åŠ¡å·²å®Œæˆæˆ–ä¸­æ­¢è¿”å›True

        """
        async with self._lock:
            current_status = self._execution_status.get(task_node_id)
            if current_status in [TaskStatus.COMPLETED, TaskStatus.ABORTED]:
                self.logger.info(
                    f"Task {task_node_id} already completed with status: {current_status.value}",
                )
                return True
            return False

    def _get_or_create_executor(
        self,
        current_task: TaskNode,
        task_node_id: str,
    ) -> "TaskNodeExecutionEngine":
        """è·å–æˆ–åˆ›å»ºä»»åŠ¡æ‰§è¡Œå¼•æ“

        Args:
            current_task: å½“å‰ä»»åŠ¡èŠ‚ç‚¹
            task_node_id: ä»»åŠ¡èŠ‚ç‚¹ID

        Returns:
            TaskNodeExecutionEngineå®ä¾‹

        """
        if task_node_id not in self._node_executors:
            self._node_executors[task_node_id] = TaskNodeExecutionEngine(
                task_node=current_task,
                user_workspace=self._user_workspace,
                message_processor=self._message_processor,
                llm_service=self._llm_service,
                tool_call_service=self._tool_call_service,
                event_bus=self._event_bus,
                config=self._config,
                agent=self._agent,  # ä¼ é€’agentå¼•ç”¨
            )
        return self._node_executors[task_node_id]

    async def _update_task_status(self, task_node_id: str, status: TaskStatus) -> None:
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€

        Args:
            task_node_id: ä»»åŠ¡èŠ‚ç‚¹ID
            status: æ–°çŠ¶æ€

        """
        await self._user_workspace.task_graph.update_task_status(task_node_id, status)
        self._execution_status[task_node_id] = status

    async def _execute_task_and_handle_completion(
        self,
        current_task: TaskNode,
        task_node_id: str,
        executor: "TaskNodeExecutionEngine",
    ) -> TaskStatus:
        """æ‰§è¡Œä»»åŠ¡å¹¶å¤„ç†å®Œæˆé€»è¾‘ï¼ˆå¸¦è¶…æ—¶é‡è¯•æœºåˆ¶ï¼‰

        Args:
            current_task: å½“å‰ä»»åŠ¡èŠ‚ç‚¹
            task_node_id: ä»»åŠ¡èŠ‚ç‚¹ID
            executor: ä»»åŠ¡æ‰§è¡Œå¼•æ“

        Returns:
            æœ€ç»ˆä»»åŠ¡çŠ¶æ€

        """
        # è¶…æ—¶é‡è¯•é…ç½®
        max_retries = 2  # æœ€å¤šé‡è¯•2æ¬¡
        base_delay = 2.0  # åŸºç¡€å»¶è¿Ÿ2ç§’

        for attempt in range(max_retries + 1):
            try:
                # æ‰§è¡Œå½“å‰ä»»åŠ¡ï¼ˆç­‰å¾…ç›´åˆ°å®Œæˆæˆ–ä¸­æ­¢ï¼‰
                await executor.execute_task()

                # æˆåŠŸæ‰§è¡Œï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                break

            except TimeoutError:
                # è¶…æ—¶é”™è¯¯å¤„ç†
                if attempt < max_retries:
                    # è®¡ç®—æŒ‡æ•°é€€é¿å»¶è¿Ÿ
                    delay = base_delay * (2**attempt)
                    self.logger.warning(
                        f"Task {task_node_id} timeout on attempt {attempt + 1}/{max_retries + 1}, retrying in {delay:.1f}s...",
                    )

                    # ç­‰å¾…åé‡è¯•ï¼Œä½¿ç”¨æ›´é•¿çš„è¶…æ—¶
                    await asyncio.sleep(delay)

                    # é‡æ–°åˆ›å»ºexecutorä»¥é¿å…çŠ¶æ€æ±¡æŸ“
                    executor = self._get_or_create_executor(current_task, task_node_id)

                    # ä¸‹æ¬¡é‡è¯•æ—¶ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´ï¼ˆ1.5å€é€’å¢ï¼‰
                    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å°†è¶…æ—¶ä¿¡æ¯ä¼ é€’ç»™executor
                    continue
                # é‡è¯•æ¬¡æ•°ç”¨å°½ï¼Œè®°å½•é”™è¯¯å¹¶è¿”å›å¤±è´¥çŠ¶æ€
                self.logger.exception(
                    f"Task {task_node_id} failed after {max_retries + 1} attempts due to timeout",
                )
                return TaskStatus.FAILED

            except (TimeoutError, OSError, RuntimeError):
                # å…¶ä»–é”™è¯¯ä¸é‡è¯•ï¼Œç›´æ¥æŠ›å‡º
                self.logger.exception(f"Task {task_node_id} encountered unexpected error: ")
                raise

        # ğŸ”§ ä¿®å¤ï¼šä¸ç®¡å½“å‰çŠ¶æ€å¦‚ä½•ï¼Œéƒ½è¦æ£€æŸ¥æ˜¯å¦æœ‰å­ä»»åŠ¡æˆ–å­å›¾éœ€è¦å¤„ç†
        # è¿™æ˜¯ä¸ºäº†é¿å…ä¸»ä»»åŠ¡æ ‡è®°ä¸ºCOMPLETEDä½†å­ä»»åŠ¡è¿˜åœ¨æ‰§è¡Œçš„æƒ…å†µ
        subtasks = await self._user_workspace.task_graph.get_subtasks(task_node_id)
        has_subtasks = bool(subtasks)
        has_subgraph = bool(current_task.sub_graph)

        if has_subtasks or has_subgraph:
            # æœ‰å­ä»»åŠ¡æˆ–å­å›¾ï¼Œéœ€è¦ç­‰å¾…å®ƒä»¬å®Œæˆ
            self.logger.info(f"Task {task_node_id} executor finished, processing {len(subtasks) if has_subtasks else 0} subtasks or subgraph before finalizing status...")
            final_status = await self._handle_subtasks_and_subgraphs(current_task, task_node_id)
        else:
            # æ²¡æœ‰å­ä»»åŠ¡æˆ–å­å›¾ï¼Œä½¿ç”¨å½“å‰ä»»åŠ¡çš„çŠ¶æ€
            final_status = current_task.status
            self.logger.info(f"Task {task_node_id} executor finished with no subtasks or subgraph, using current status: {final_status.value}")

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        await self._update_task_status(task_node_id, final_status)
        self.logger.info(
            f"Task {task_node_id} execution completed with status: {final_status.value}",
        )
        return final_status

    async def _handle_subtasks_and_subgraphs(
        self,
        current_task: TaskNode,
        task_node_id: str,
    ) -> TaskStatus:
        """å¤„ç†å­ä»»åŠ¡å’Œå­å›¾çš„æ‰§è¡Œ

        Args:
            current_task: å½“å‰ä»»åŠ¡èŠ‚ç‚¹
            task_node_id: ä»»åŠ¡èŠ‚ç‚¹ID

        Returns:
            æœ€ç»ˆçŠ¶æ€

        """
        # è·å–å­ä»»åŠ¡
        subtasks = await self._user_workspace.task_graph.get_subtasks(task_node_id)

        if subtasks:
            # å¹¶è¡Œæ‰§è¡Œå­ä»»åŠ¡å¹¶æ£€æŸ¥ç»“æœ
            return await self._execute_subtasks_and_check_status(subtasks)

        # æ²¡æœ‰å­ä»»åŠ¡ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å­å›¾éœ€è¦æ‰§è¡Œ
        if current_task.sub_graph:
            # é€’å½’æ‰§è¡Œå­å›¾
            return await self.execute_task_graph(current_task.sub_graph)

        # æ²¡æœ‰å­ä»»åŠ¡ä¹Ÿæ²¡æœ‰å­å›¾
        self.logger.info(
            f"Task {task_node_id} executor finished without explicit completion, checking status...",
        )
        return current_task.status

    async def _execute_subtasks_and_check_status(self, subtasks: list[TaskNode]) -> TaskStatus:
        """å¹¶è¡Œæ‰§è¡Œå­ä»»åŠ¡å¹¶æ£€æŸ¥çŠ¶æ€

        Args:
            subtasks: å­ä»»åŠ¡åˆ—è¡¨

        Returns:
            ä»»åŠ¡çŠ¶æ€ï¼ˆCOMPLETEDæˆ–FAILEDï¼‰

        """
        # å¹¶è¡Œæ‰§è¡Œå­ä»»åŠ¡
        subtask_results = await self._execute_subtasks_parallel(subtasks)

        # æ£€æŸ¥å­ä»»åŠ¡æ‰§è¡Œç»“æœ
        if all(result == TaskStatus.COMPLETED for result in subtask_results):
            return TaskStatus.COMPLETED
        # å¦‚æœæœ‰å­ä»»åŠ¡å¤±è´¥ï¼Œçˆ¶ä»»åŠ¡ä¹Ÿæ ‡è®°ä¸ºå¤±è´¥
        return TaskStatus.FAILED

    async def _handle_task_cancellation(self, task_node_id: str) -> None:
        """å¤„ç†ä»»åŠ¡å–æ¶ˆ

        Args:
            task_node_id: ä»»åŠ¡èŠ‚ç‚¹ID

        Raises:
            asyncio.CancelledError: é‡æ–°æŠ›å‡ºå–æ¶ˆå¼‚å¸¸

        """
        self.logger.info(f"Task {task_node_id} was cancelled")
        await self._update_task_status(task_node_id, TaskStatus.ABORTED)
        raise  # é‡æ–°æŠ›å‡ºè®©ä¸Šå±‚å¤„ç†

    async def _handle_task_error(
        self,
        task_node_id: str,
        error: Exception,
        error_type: str,
    ) -> TaskStatus:
        """å¤„ç†ä»»åŠ¡æ‰§è¡Œé”™è¯¯

        Args:
            task_node_id: ä»»åŠ¡èŠ‚ç‚¹ID
            error: å¼‚å¸¸å¯¹è±¡
            error_type: é”™è¯¯ç±»å‹æè¿°

        Returns:
            TaskStatus.FAILED

        """
        self.logger.error(
            f"{error_type.capitalize()} executing task {task_node_id}: {error}",
            exc_info=True,
        )
        await self._update_task_status(task_node_id, TaskStatus.FAILED)
        return TaskStatus.FAILED

    async def _execute_subtasks_parallel(self, subtasks: list[TaskNode]) -> list[TaskStatus]:
        """å¹¶è¡Œæ‰§è¡Œå­ä»»åŠ¡ï¼ˆå—ä¿¡å·é‡é™åˆ¶æœ€å¤§å¹¶è¡Œæ•°ï¼‰

        Args:
            subtasks: å­ä»»åŠ¡åˆ—è¡¨

        Returns:
            å­ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€åˆ—è¡¨

        """
        # åˆ›å»ºæ‰§è¡Œä»»åŠ¡
        execution_tasks = [asyncio.create_task(self._execute_subtask_with_semaphore(subtask)) for subtask in subtasks]

        # è®°å½•æ‰§è¡Œä»»åŠ¡
        for subtask, task in zip(subtasks, execution_tasks, strict=False):
            self._execution_tasks[subtask.task_node_id] = task

        try:
            # ç­‰å¾…æ‰€æœ‰å­ä»»åŠ¡å®Œæˆ
            results = await asyncio.gather(*execution_tasks, return_exceptions=True)
            return self._process_subtask_results(results, subtasks)

        finally:
            # æ¸…ç†æ‰§è¡Œä»»åŠ¡
            for subtask in subtasks:
                self._execution_tasks.pop(subtask.task_node_id, None)

    async def _execute_subtask_with_semaphore(self, subtask: TaskNode) -> TaskStatus:
        """ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶è¡Œçš„ä»»åŠ¡æ‰§è¡Œ

        Args:
            subtask: å­ä»»åŠ¡èŠ‚ç‚¹

        Returns:
            ä»»åŠ¡çŠ¶æ€

        """
        async with self._parallel_semaphore:
            self.logger.info(
                f"Starting subtask {subtask.task_node_id} (max_parallel: {self._max_parallel_tasks})",
            )
            try:
                result = await self._execute_task_graph_recursive(subtask)
                self.logger.info(
                    f"Completed subtask {subtask.task_node_id} with status: {result.value}",
                )
                return result
            except asyncio.CancelledError:
                self.logger.info(f"Subtask {subtask.task_node_id} was cancelled")
                return TaskStatus.ABORTED
            except (TaskExecutionError, ToolExecutionError, ValueError, KeyError) as e:
                self.logger.error(
                    f"Subtask {subtask.task_node_id} failed with business error: {e}",
                    exc_info=True,
                )
                return TaskStatus.FAILED
            except (
                TaskNotFoundError,
                TaskStateError,
                ValidationError,
                StorageError,
                ConfigurationError,
                CheckpointError,
            ) as e:
                self.logger.error(
                    f"Subtask {subtask.task_node_id} failed with error: {e}",
                    exc_info=True,
                )
                return TaskStatus.FAILED

    def _process_subtask_results(
        self,
        results: list[Any],
        subtasks: list[TaskNode],
    ) -> list[TaskStatus]:
        """å¤„ç†å­ä»»åŠ¡æ‰§è¡Œç»“æœ

        Args:
            results: æ‰§è¡Œç»“æœåˆ—è¡¨
            subtasks: å­ä»»åŠ¡åˆ—è¡¨

        Returns:
            ä»»åŠ¡çŠ¶æ€åˆ—è¡¨

        """
        status_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                if isinstance(result, asyncio.CancelledError):
                    self.logger.info(f"Subtask {subtasks[i].task_node_id} was cancelled")
                    status_results.append(TaskStatus.ABORTED)
                else:
                    self.logger.error(
                        f"Subtask {subtasks[i].task_node_id} failed with exception: {result}",
                    )
                    status_results.append(TaskStatus.FAILED)
            elif isinstance(result, TaskStatus):
                status_results.append(result)
            else:
                self.logger.warning(
                    f"Unexpected result type for subtask {subtasks[i].task_node_id}: {type(result)}",
                )
                status_results.append(TaskStatus.FAILED)

        return status_results

    def set_max_parallel_tasks(self, max_parallel: int) -> None:
        """è®¾ç½®æœ€å¤§å¹¶è¡Œä»»åŠ¡èŠ‚ç‚¹æ•°

        Args:
            max_parallel: æœ€å¤§å¹¶è¡Œæ•°ï¼ˆå¿…é¡» >= 1ï¼‰

        """
        if max_parallel < 1:
            raise ValueError(f"max_parallel must be >= 1, got {max_parallel}")

        old_max = self._max_parallel_tasks
        self._max_parallel_tasks = max_parallel

        # åˆ›å»ºæ–°çš„ä¿¡å·é‡ï¼ˆæ—§ä¿¡å·é‡ä»åœ¨ä½¿ç”¨ä¸­çš„ä»»åŠ¡ä¼šç»§ç»­ä½¿ç”¨æ—§çš„ï¼‰
        self._parallel_semaphore = asyncio.Semaphore(self._max_parallel_tasks)

        self.logger.info(f"Max parallel tasks updated from {old_max} to {self._max_parallel_tasks}")

    def get_max_parallel_tasks(self) -> int:
        """è·å–å½“å‰æœ€å¤§å¹¶è¡Œä»»åŠ¡èŠ‚ç‚¹æ•°

        Returns:
            æœ€å¤§å¹¶è¡Œæ•°

        """
        return self._max_parallel_tasks

    async def process_message(self, message: UserInputMessage) -> Any:
        """å¤„ç†æ¶ˆæ¯

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯

        Returns:
            å¤„ç†ç»“æœ

        """
        task_node_id = message.task_node_id

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯
        await self._add_message_to_conversation(message)

        # ç¡®ä¿æ ¹ä»»åŠ¡å­˜åœ¨
        root_task = await self._ensure_root_task_exists(message)

        # è·å–ä»»åŠ¡èŠ‚ç‚¹
        task_node, task_node_id = self._get_or_create_task_node(task_node_id, root_task)

        # è·å–æˆ–åˆ›å»ºæ‰§è¡Œå¼•æ“
        self._node_executors[task_node_id] = TaskNodeExecutionEngine(
            task_node=task_node,
            user_workspace=self._user_workspace,
            message_processor=self._message_processor,
            llm_service=self._llm_service,
            tool_call_service=self._tool_call_service,
            event_bus=self._event_bus,
            config=self._config,
            agent=self._agent,
        )

        # åŒæ­¥ä»»åŠ¡çŠ¶æ€
        if task_node_id:
            await self._sync_task_status(task_node_id)

        return None

    async def _add_message_to_conversation(self, message: UserInputMessage) -> None:
        """æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å½“å‰å¯¹è¯

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯

        """
        message_content = getattr(message, "text", str(message))

        if not self._user_workspace.current_conversation:
            self.logger.warning(
                "No current conversation found, user message not added to conversation history",
            )
            return

        from dawei.entity.lm_messages import UserMessage

        self._user_workspace.current_conversation.say(UserMessage(content=message_content))
        self.logger.info(
            f"Added user message to conversation {self._user_workspace.current_conversation.id}. Message count: {self._user_workspace.current_conversation.message_count}",
        )

        # ä¿å­˜å¯¹è¯
        try:
            save_success = await self._user_workspace.save_current_conversation()
            if save_success:
                self.logger.info("Successfully saved conversation before processing")
            else:
                self.logger.warning("Failed to save conversation before processing")
        except Exception as save_error:
            self.logger.error(f"Error saving conversation: {save_error}", exc_info=True)

    async def _ensure_root_task_exists(self, message: UserInputMessage) -> TaskNode:
        """ç¡®ä¿æ ¹ä»»åŠ¡å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯

        Returns:
            æ ¹ä»»åŠ¡èŠ‚ç‚¹

        """
        root_task = await self._user_workspace.task_graph.get_root_task()
        if root_task:
            return root_task

        # åˆ›å»ºæ ¹ä»»åŠ¡
        from dawei.task_graph.task_node_data import TaskData

        root_task_id = str(uuid.uuid4())
        task_data = TaskData(
            task_node_id=root_task_id,
            description=message,
            mode=self._user_workspace.mode,
            context=self._user_workspace.create_task_context(),
        )
        root_task = await self._user_workspace.task_graph.create_root_task(task_data)
        self.logger.info(
            f"Created root task: {root_task_id} with mode: {self._user_workspace.mode}",
        )
        return root_task

    def _get_or_create_task_node(
        self,
        task_node_id: str | None,
        root_task: TaskNode,
    ) -> tuple[TaskNode, str]:
        """è·å–æˆ–åˆ›å»ºä»»åŠ¡èŠ‚ç‚¹

        Args:
            task_node_id: ä»»åŠ¡ID
            root_task: æ ¹ä»»åŠ¡

        Returns:
            (ä»»åŠ¡èŠ‚ç‚¹, ä»»åŠ¡ID)å…ƒç»„

        """
        if task_node_id and task_node_id in self._node_executors:
            # ä½¿ç”¨å·²æœ‰çš„æ‰§è¡Œå¼•æ“å¯¹åº”çš„ä»»åŠ¡èŠ‚ç‚¹
            return self._node_executors[task_node_id].task_node, task_node_id
        if task_node_id:
            # å°è¯•è·å–ä»»åŠ¡èŠ‚ç‚¹ï¼ˆå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨æ ¹ä»»åŠ¡ï¼‰
            try:
                # Note: This assumes get_task is async, but the parent context may vary
                # For now, we'll use root_task as fallback
                return root_task, root_task.task_node_id
            except Exception:
                return root_task, root_task.task_node_id
        else:
            # ä½¿ç”¨æ ¹ä»»åŠ¡
            return root_task, root_task.task_node_id

    async def _sync_task_status(self, task_node_id: str) -> None:
        """åŒæ­¥ä»»åŠ¡çŠ¶æ€

        Args:
            task_node_id: ä»»åŠ¡ID

        """
        try:
            # æ£€æŸ¥ task_node_id æ˜¯å¦æœ‰æ•ˆ
            if not task_node_id or task_node_id is None:
                return

            # æ£€æŸ¥ task_graph æ˜¯å¦å­˜åœ¨
            if not self._user_workspace.task_graph:
                return

            # è·å–æ‰§è¡Œå¼•æ“ä¸­çš„ä»»åŠ¡çŠ¶æ€
            if task_node_id in self._node_executors:
                executor = self._node_executors[task_node_id]
                await executor.get_execution_status()

                # è·å–ä»»åŠ¡å›¾ä¸­çš„ä»»åŠ¡çŠ¶æ€
                task_node = await self._user_workspace.task_graph.get_task(task_node_id)
                if task_node:
                    # å¦‚æœçŠ¶æ€ä¸ä¸€è‡´ï¼ŒåŒæ­¥åˆ°ä»»åŠ¡å›¾
                    if task_node.status != self._execution_status.get(task_node_id):
                        await self._user_workspace.task_graph.update_task_status(
                            task_node_id,
                            task_node.status,
                        )
                        self._execution_status[task_node_id] = task_node.status

        except (TaskNotFoundError, TaskStateError) as e:
            self.logger.error(f"Task error syncing status for {task_node_id}: {e}", exc_info=True)
            raise  # Fast fail: re-raise task errors
        except StorageError as e:
            self.logger.error(
                f"Storage error syncing status for {task_node_id}: {e}",
                exc_info=True,
            )
            raise  # Fast fail: re-raise storage errors
        except (OSError, ConnectionError) as e:
            # ä½œä¸ºæœ€åçš„ä¿éšœï¼Œä½†è®°å½•ä¸ºæœªé¢„æœŸçš„é”™è¯¯
            self.logger.error(
                f"Unexpected error syncing task status for {task_node_id}: {e}",
                exc_info=True,
            )
            raise  # Fast fail: re-raise unexpected errors

    async def cancel_task_execution(self, task_node_id: str) -> bool:
        """å–æ¶ˆä»»åŠ¡æ‰§è¡Œ

        Args:
            task_node_id: ä»»åŠ¡ID

        Returns:
            æ˜¯å¦æˆåŠŸå–æ¶ˆ

        """
        try:
            # å–æ¶ˆæ‰§è¡Œä»»åŠ¡
            if task_node_id in self._execution_tasks:
                self._execution_tasks[task_node_id].cancel()
                del self._execution_tasks[task_node_id]

            # å–æ¶ˆèŠ‚ç‚¹æ‰§è¡Œå¼•æ“
            if task_node_id in self._node_executors:
                await self._node_executors[task_node_id].cancel_task_execution()
                # æ¸…ç†å¼•æ“å¼•ç”¨,é˜²æ­¢å†…å­˜æ³„æ¼
                del self._node_executors[task_node_id]

            # æ¸…ç†çŠ¶æ€
            if task_node_id in self._execution_status:
                del self._execution_status[task_node_id]

            self.logger.info(f"Task execution cancelled: {task_node_id}")
            return True

        except (TaskNotFoundError, TaskStateError):
            self.logger.exception("Task error cancelling {task_node_id}: ")
            return False
        except KeyError as e:
            self.logger.warning(f"Task {task_node_id} not found for cancellation: {e}")
            return True  # å¦‚æœä»»åŠ¡ä¸å­˜åœ¨ï¼Œè®¤ä¸ºå·²ç»å–æ¶ˆ
        except (OSError, RuntimeError) as e:
            # ä½œä¸ºæœ€åçš„ä¿éšœ
            self.logger.error(
                f"Unexpected error cancelling task execution for {task_node_id}: {e}",
                exc_info=True,
            )
            raise  # Fast fail: re-raise unexpected errors

    async def get_task_execution_status(self, task_node_id: str) -> dict[str, Any]:
        """è·å–ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€

        Args:
            task_node_id: ä»»åŠ¡ID

        Returns:
            æ‰§è¡ŒçŠ¶æ€ä¿¡æ¯

        """
        try:
            if task_node_id in self._node_executors:
                executor = self._node_executors[task_node_id]
                return await executor.get_execution_status()
            return {
                "task_node_id": task_node_id,
                "is_executing": False,
                "last_checkpoint_time": 0,
                "execution_time": 0,
            }

        except (KeyError, TaskNotFoundError) as e:
            self.logger.warning(f"Task {task_node_id} not found: {e}")
            return {
                "task_node_id": task_node_id,
                "is_executing": False,
                "last_checkpoint_time": 0,
                "execution_time": 0,
            }
        except (KeyError, AttributeError, RuntimeError) as e:
            self.logger.error(
                f"Unexpected error getting task execution status for {task_node_id}: {e}",
                exc_info=True,
            )
            raise  # Fast fail: re-raise unexpected errors instead of returning empty dict

    async def get_current_step_description(self) -> str:
        """è·å–å½“å‰æ­£åœ¨æ‰§è¡Œçš„æ­¥éª¤æè¿°

        Returns:
            str: å½“å‰æ­¥éª¤æè¿°

        """
        if self._current_task_node_id:
            # å°è¯•ä»ä»»åŠ¡å›¾è·å–ä»»åŠ¡èŠ‚ç‚¹ä¿¡æ¯
            try:
                task_node = await self._user_workspace.task_graph.get_task(
                    self._current_task_node_id,
                )
                if task_node:
                    return f"æ‰§è¡Œä»»åŠ¡: {task_node.description or task_node.task_node_id}"
            except (TaskNotFoundError, StorageError) as e:
                self.logger.debug(f"Could not retrieve task details for step description: {e}")
            except (ValueError, RuntimeError) as e:
                self.logger.error(
                    f"Unexpected error getting current step description: {e}",
                    exc_info=True,
                )

        return "æ­£åœ¨æ‰§è¡Œ"

    async def stop(self) -> str:
        """åœæ­¢ä»»åŠ¡å›¾æ‰§è¡Œ

        Returns:
            str: åœæ­¢ç»“æœçš„æ‘˜è¦

        """
        self.logger.info("Stopping task graph execution")

        # å–æ¶ˆæ‰€æœ‰æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡
        cancelled_count = 0
        for _task_node_id, task in self._execution_tasks.items():
            if not task.done():
                task.cancel()
                cancelled_count += 1

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼ˆè¢«å–æ¶ˆï¼‰
        if cancelled_count > 0:
            await asyncio.gather(*self._execution_tasks.values(), return_exceptions=True)

        result_summary = f"å·²åœæ­¢ {cancelled_count} ä¸ªæ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡"

        # æ¸…ç†æ‰§è¡Œå¼•æ“
        self._node_executors.clear()
        self._execution_status.clear()
        self._execution_tasks.clear()

        self.logger.info(f"Task graph execution stopped: {result_summary}")
        return result_summary

    async def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        try:
            # å–æ¶ˆæ‰€æœ‰æ‰§è¡Œä»»åŠ¡
            for _task_node_id, task in self._execution_tasks.items():
                if not task.done():
                    task.cancel()

            # æ¸…ç†æ‰§è¡Œå¼•æ“
            self._node_executors.clear()
            self._execution_status.clear()
            self._execution_tasks.clear()

            self.logger.info("Task graph execution engine cleaned up")

        except (asyncio.CancelledError, RuntimeError) as e:
            self.logger.warning(f"Cleanup interrupted or runtime error: {e}")
            raise  # Fast fail: re-raise cleanup errors
        except OSError as e:
            self.logger.error(f"Unexpected error during cleanup: {e}", exc_info=True)
            raise  # Fast fail: re-raise unexpected cleanup errors
