# Copyright (c) 2025 æ ¼å¾‹è‡³å¾®
# SPDX-License-Identifier: AGPL-3.0-only

"""TaskGraph æŒä¹…åŒ–ç®¡ç†å™¨
è‡ªåŠ¨ç›‘å¬ä»»åŠ¡å›¾äº‹ä»¶å¹¶å¼‚æ­¥ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿ

è®¾è®¡åŸåˆ™ï¼š
1. äº‹ä»¶é©±åŠ¨ï¼šç›‘å¬ä»»åŠ¡å›¾äº‹ä»¶ï¼Œè‡ªåŠ¨è§¦å‘ä¿å­˜
2. å¼‚æ­¥ä¿å­˜ï¼šä¸é˜»å¡ä¸»æµç¨‹
3. å»é‡æœºåˆ¶ï¼šç›¸åŒèµ„æºçŸ­æ—¶é—´å†…åªä¿å­˜ä¸€æ¬¡
4. é”™è¯¯éš”ç¦»ï¼šä¿å­˜å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
"""

import asyncio
import contextlib
from datetime import UTC, datetime, timezone
from pathlib import Path
from typing import Any

from dawei.core.events import emit_typed_event  # ğŸ”´ ä¿®å¤ï¼šåˆ é™¤ CORE_EVENT_BUS å¯¼å…¥
from dawei.logg.logging import get_logger
from dawei.workspace.persistence_manager import WorkspacePersistenceManager


class TaskGraphPersistenceManager:
    """TaskGraph è‡ªåŠ¨æŒä¹…åŒ–ç®¡ç†å™¨

    èŒè´£ï¼š
    1. ç›‘å¬ä»»åŠ¡å›¾äº‹ä»¶ï¼ˆåˆ›å»ºã€æ›´æ–°ã€çŠ¶æ€å˜åŒ–ï¼‰
    2. å¼‚æ­¥ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿ
    3. ç®¡ç†ä¿å­˜é˜Ÿåˆ—å’Œå»é‡
    4. é”™è¯¯å¤„ç†å’Œé‡è¯•

    ä½¿ç”¨æ–¹å¼ï¼š
        persistence_manager = TaskGraphPersistenceManager(
            workspace_path="/path/to/workspace",
            event_bus=event_bus
        )
        await persistence_manager.start()

        # ... ä»»åŠ¡å›¾æ“ä½œä¼šè‡ªåŠ¨è§¦å‘ä¿å­˜ ...

        await persistence_manager.stop()
    """

    def __init__(self, workspace_path: str, event_bus=None, debounce_seconds: float = 1.0):
        """åˆå§‹åŒ–æŒä¹…åŒ–ç®¡ç†å™¨

        Args:
            workspace_path: å·¥ä½œåŒºè·¯å¾„
            event_bus: äº‹ä»¶æ€»çº¿ï¼ˆå¯é€‰ï¼Œå…è®¸ä¸º Noneï¼Œç¨åé€šè¿‡ property setter è®¾ç½®ï¼‰
            debounce_seconds: é˜²æŠ–æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œç›¸åŒèµ„æºåœ¨æ­¤æ—¶é—´å†…åªä¿å­˜ä¸€æ¬¡

        """
        self.workspace_path = Path(workspace_path)
        self._event_bus = event_bus  # ğŸ”§ ä¿®å¤ï¼šå…è®¸ Noneï¼Œç¨åè®¾ç½®
        self.persistence_manager = WorkspacePersistenceManager(str(self.workspace_path))
        self.logger = get_logger(__name__)

        # ä¿å­˜é˜Ÿåˆ—å’Œå»é‡
        self._save_queue: asyncio.Queue = asyncio.Queue()
        self._pending_saves: set[str] = set()
        self._save_task: asyncio.Task | None = None
        self._debounce_seconds = debounce_seconds

        # ç»Ÿè®¡ä¿¡æ¯
        self._save_count = 0
        self._error_count = 0
        self._last_save_time: datetime | None = None

        # è¿è¡ŒçŠ¶æ€
        self._started = False
        self._event_listeners_registered = False  # ğŸ”´ æ–°å¢ï¼šè¿½è¸ªæ˜¯å¦å·²æ³¨å†Œç›‘å¬å™¨

    @property
    def event_bus(self):
        """è·å– event_bus"""
        return self._event_bus

    @event_bus.setter
    def event_bus(self, value):
        """è®¾ç½® event_bus å¹¶æ³¨å†Œç›‘å¬å™¨ï¼ˆå¦‚æœå·²å¯åŠ¨ï¼‰"""
        self._event_bus = value

        # å¦‚æœç®¡ç†å™¨å·²å¯åŠ¨ä¸” event_bus ä¸ä¸º Noneï¼Œç«‹å³æ³¨å†Œç›‘å¬å™¨
        if self._started and value is not None and not self._event_listeners_registered:
            self._setup_event_listeners()

    async def start(self):
        """å¯åŠ¨æŒä¹…åŒ–æœåŠ¡"""
        if self._started:
            self.logger.warning("Persistence manager already started")
            return

        try:
            # ğŸ”§ ä¿®å¤ï¼šåªåœ¨ event_bus ä¸ä¸º None æ—¶æ³¨å†Œç›‘å¬å™¨
            if self._event_bus is not None:
                self._setup_event_listeners()
            else:
                self.logger.info("Event bus is None, listeners will be registered when event_bus is set")

            # å¯åŠ¨åå°ä¿å­˜ä»»åŠ¡
            self._save_task = asyncio.create_task(self._save_loop())
            self._started = True

            self.logger.info(
                f"TaskGraph persistence manager started for workspace: {self.workspace_path}, debounce={self._debounce_seconds}s",
            )

        except Exception as e:
            self.logger.error(f"Failed to start persistence manager: {e}", exc_info=True)
            raise

    def _setup_event_listeners(self):
        """è®¾ç½®äº‹ä»¶ç›‘å¬å™¨"""
        from dawei.core.events import TaskEventType

        # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥ event_bus æ˜¯å¦å¯ç”¨
        if self._event_bus is None:
            self.logger.warning("Cannot register event listeners: event_bus is None")
            return

        # ç›‘å¬ä»»åŠ¡å›¾åˆ›å»ºäº‹ä»¶
        self._event_bus.add_handler(TaskEventType.TASK_GRAPH_CREATED, self._on_task_graph_created)

        # ç›‘å¬ä»»åŠ¡å›¾æ›´æ–°äº‹ä»¶
        self._event_bus.add_handler(TaskEventType.TASK_GRAPH_UPDATED, self._on_task_graph_updated)

        # ç›‘å¬ä»»åŠ¡çŠ¶æ€å˜åŒ–äº‹ä»¶ï¼ˆè§¦å‘æ•´ä¸ªä»»åŠ¡å›¾ä¿å­˜ï¼‰
        self._event_bus.add_handler(TaskEventType.STATE_CHANGED, self._on_state_changed)

        self._event_listeners_registered = True  # ğŸ”´ æ–°å¢ï¼šæ ‡è®°å·²æ³¨å†Œ
        self.logger.debug("Event listeners registered")

    async def _on_task_graph_created(self, event: Any):
        """TaskGraph åˆ›å»ºäº‹ä»¶å¤„ç†"""
        try:
            data = self._extract_event_data(event)
            task_graph_id = data.get("task_graph_id")

            if task_graph_id:
                await self._queue_save("task_graph", task_graph_id)
                self.logger.info(f"Queued save for new task graph: {task_graph_id}")

        except Exception as e:
            self.logger.error(f"Error handling TASK_GRAPH_CREATED event: {e}", exc_info=True)

    async def _on_task_graph_updated(self, event: Any):
        """TaskGraph æ›´æ–°äº‹ä»¶å¤„ç†"""
        try:
            data = self._extract_event_data(event)
            task_graph_id = data.get("task_graph_id")

            if task_graph_id:
                await self._queue_save("task_graph", task_graph_id)
                self.logger.debug(f"Queued save for updated task graph: {task_graph_id}")

        except Exception as e:
            self.logger.error(f"Error handling TASK_GRAPH_UPDATED event: {e}", exc_info=True)

    async def _on_state_changed(self, event: Any):
        """ä»»åŠ¡çŠ¶æ€å˜åŒ–äº‹ä»¶å¤„ç†ï¼ˆè§¦å‘æ•´ä¸ªä»»åŠ¡å›¾ä¿å­˜ï¼‰"""
        try:
            data = self._extract_event_data(event)
            # ä»çŠ¶æ€å˜åŒ–äº‹ä»¶ä¸­è·å– task_graph_id
            # å¯èƒ½éœ€è¦ä»ä¸Šä¸‹æ–‡ä¸­æ¨æ–­æˆ–ä½¿ç”¨ task_id æŸ¥æ‰¾
            task_graph_id = data.get("task_graph_id")

            # å¦‚æœæ²¡æœ‰ç›´æ¥æä¾› task_graph_idï¼Œå¯ä»¥å°è¯•å…¶ä»–æ–¹å¼è·å–
            if not task_graph_id:
                # å¯èƒ½éœ€è¦ä» UserWorkspace è·å–
                # è¿™é‡Œæš‚æ—¶è·³è¿‡ï¼Œç­‰å¾…å…¶ä»–äº‹ä»¶è§¦å‘ä¿å­˜
                return

            await self._queue_save("task_graph", task_graph_id)
            self.logger.debug(f"Queued save for task graph on state change: {task_graph_id}")

        except Exception as e:
            self.logger.error(f"Error handling STATE_CHANGED event: {e}", exc_info=True)

    def _extract_event_data(self, event: Any) -> dict[str, Any]:
        """æå–äº‹ä»¶æ•°æ®ï¼ˆå…¼å®¹ä¸åŒçš„äº‹ä»¶æ ¼å¼ï¼‰"""
        try:
            # å°è¯•ä»å¼ºç±»å‹äº‹ä»¶ä¸­æå–
            if hasattr(event, "data") and hasattr(event.data, "get_event_data"):
                return event.data.get_event_data()
            # ä»æ™®é€šäº‹ä»¶ä¸­æå–
            if hasattr(event, "data"):
                return event.data if isinstance(event.data, dict) else {}
            # äº‹ä»¶æœ¬èº«å°±æ˜¯æ•°æ®
            if isinstance(event, dict):
                return event
            return {}
        except Exception as e:
            self.logger.warning(f"Error extracting event data: {e}")
            return {}

    async def _queue_save(self, resource_type: str, resource_id: str):
        """é˜Ÿåˆ—åŒ–ä¿å­˜è¯·æ±‚ï¼ˆå¸¦é˜²æŠ–å»é‡ï¼‰"""
        key = f"{resource_type}:{resource_id}"

        # å¦‚æœå·²ç»åœ¨å¾…ä¿å­˜é˜Ÿåˆ—ä¸­ï¼Œè·³è¿‡
        if key in self._pending_saves:
            self.logger.debug(f"Save already pending for {key}, skipping duplicate request")
            return

        # æ·»åŠ åˆ°å¾…ä¿å­˜é›†åˆå’Œé˜Ÿåˆ—
        self._pending_saves.add(key)
        await self._save_queue.put((resource_type, resource_id, key))

        self.logger.debug(f"Queued save request: {key}")

    async def _save_loop(self):
        """åå°ä¿å­˜å¾ªç¯"""
        self.logger.info("Save loop started")

        try:
            while True:
                try:
                    # ä»é˜Ÿåˆ—è·å–ä¿å­˜è¯·æ±‚
                    resource_type, resource_id, key = await self._save_queue.get()

                    # é˜²æŠ–ï¼šç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œçœ‹çœ‹æ˜¯å¦æœ‰æ›´å¤šæ›´æ–°
                    await asyncio.sleep(self._debounce_seconds)

                    # æ‰§è¡Œä¿å­˜
                    await self._perform_save(resource_type, resource_id)

                    # ä»å¾…ä¿å­˜é›†åˆç§»é™¤
                    self._pending_saves.discard(key)

                    # æ›´æ–°ç»Ÿè®¡
                    self._save_count += 1
                    self._last_save_time = datetime.now(UTC)

                    self.logger.debug(
                        f"Save completed: {key} (total: {self._save_count}, errors: {self._error_count})",
                    )

                except asyncio.CancelledError:
                    self.logger.info("Save loop cancelled")
                    break
                except Exception as e:
                    self.logger.error(f"Error in save loop iteration: {e}", exc_info=True)
                    self._error_count += 1
                    # ä»å¾…ä¿å­˜é›†åˆç§»é™¤ï¼Œé¿å…é˜»å¡åç»­ä¿å­˜
                    self._pending_saves.discard(key)

        except Exception as e:
            self.logger.error(f"Fatal error in save loop: {e}", exc_info=True)

    async def _perform_save(self, resource_type: str, resource_id: str):
        """æ‰§è¡Œå®é™…çš„ä¿å­˜æ“ä½œ"""
        try:
            if resource_type == "task_graph":
                await self._save_task_graph(resource_id)
            else:
                self.logger.warning(f"Unknown resource type: {resource_type}")

        except Exception as e:
            self.logger.error(f"Failed to save {resource_type} {resource_id}: {e}", exc_info=True)
            # ä¸é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…ä¸­æ–­ä¿å­˜å¾ªç¯

    async def _save_task_graph(self, task_graph_id: str):
        """è§¦å‘ä»»åŠ¡å›¾ä¿å­˜

        æ³¨æ„ï¼šè¿™é‡Œé€šè¿‡äº‹ä»¶æ€»çº¿å‘é€è¯·æ±‚ï¼Œè®© UserWorkspace å¤„ç†å®é™…ä¿å­˜
        å› ä¸º TaskGraph å®ä¾‹åœ¨ UserWorkspace ä¸­ç»´æŠ¤
        """
        try:
            from dawei.core.events import TaskEventType

            # é€šè¿‡äº‹ä»¶æ€»çº¿è¯·æ±‚æŒä¹…åŒ–ï¼ˆä½¿ç”¨æšä¸¾ï¼‰
            await emit_typed_event(
                TaskEventType.PERSIST_TASK_GRAPH,
                {
                    "task_graph_id": task_graph_id,
                    "timestamp": datetime.now(UTC).isoformat(),
                },
                self.event_bus,  # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ  event_bus å‚æ•°
                task_id=task_graph_id,
            )

            self.logger.debug(f"Triggered save for task graph: {task_graph_id}")

        except Exception as e:
            self.logger.error(
                f"Error triggering task graph save for {task_graph_id}: {e}",
                exc_info=True,
            )
            raise

    async def stop(self):
        """åœæ­¢æŒä¹…åŒ–æœåŠ¡"""
        if not self._started:
            self.logger.warning("Persistence manager not started")
            return

        try:
            # 1. å…ˆç­‰å¾…é˜Ÿåˆ—ä¸­çš„ä¿å­˜å®Œæˆï¼ˆåœ¨å–æ¶ˆä»»åŠ¡ä¹‹å‰ï¼‰
            timeout = 5.0  # 5ç§’è¶…æ—¶
            start_time = datetime.now(UTC)

            while self._pending_saves and (datetime.now(UTC) - start_time).total_seconds() < timeout:
                self.logger.info(
                    f"Waiting for {len(self._pending_saves)} pending saves to complete...",
                )
                await asyncio.sleep(0.5)

            if self._pending_saves:
                self.logger.warning(f"Stop timeout: {len(self._pending_saves)} saves still pending")

            # 2. å–æ¶ˆåå°ä»»åŠ¡ï¼ˆåœ¨ç­‰å¾…å®Œæˆä¹‹åï¼‰
            if self._save_task and not self._save_task.done():
                self._save_task.cancel()
                with contextlib.suppress(asyncio.CancelledError):
                    await self._save_task

            self._started = False

            self.logger.info(
                f"TaskGraph persistence manager stopped. Total saves: {self._save_count}, errors: {self._error_count}",
            )

        except Exception as e:
            self.logger.error(f"Error stopping persistence manager: {e}", exc_info=True)

    async def force_save(self, task_graph_id: str):
        """å¼ºåˆ¶ç«‹å³ä¿å­˜æŒ‡å®šä»»åŠ¡å›¾ï¼ˆåŒæ­¥ç­‰å¾…å®Œæˆï¼‰"""
        await self._queue_save("task_graph", task_graph_id)

        # ç­‰å¾…ä¿å­˜å®Œæˆ
        key = f"task_graph:{task_graph_id}"
        timeout = 10.0  # 10ç§’è¶…æ—¶
        start_time = datetime.now(UTC)

        while key in self._pending_saves and (datetime.now(UTC) - start_time).total_seconds() < timeout:
            await asyncio.sleep(0.1)

        if key in self._pending_saves:
            raise TimeoutError(f"Force save timeout for task graph: {task_graph_id}")

        self.logger.info(f"Force save completed for task graph: {task_graph_id}")

    def get_stats(self) -> dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "started": self._started,
            "total_saves": self._save_count,
            "error_count": self._error_count,
            "pending_saves": len(self._pending_saves),
            "last_save_time": self._last_save_time.isoformat() if self._last_save_time else None,
            "debounce_seconds": self._debounce_seconds,
            "queue_size": self._save_queue.qsize() if self._save_queue else 0,
        }
